## Visualisation et compréhension des réseaux de neurones convolutionnels

### Résumé du papier de Matthew D. Zeiler et Rob Fergus

### Introduction

Depuis leur introduction par LeCun et al. dans les années 1990, les réseaux de neurones convolutionnels (convnets) ont montré une performance exceptionnelle dans des tâches telles que la classification de chiffres manuscrits et la détection de visages. Plus récemment, ces réseaux ont démontré des résultats impressionnants sur des tâches de classification visuelle plus complexes, notamment sur le benchmark ImageNet.

### Objectif de l'étude

L'étude de Zeiler et Fergus vise à explorer pourquoi les modèles de convnets fonctionnent si bien et comment ils peuvent être améliorés. Pour ce faire, ils introduisent une technique de visualisation novatrice qui permet de comprendre les couches de caractéristiques intermédiaires et le fonctionnement du classificateur. Cette technique permet de diagnostiquer les architectures de modèles et d'améliorer les performances sur le benchmark ImageNet.

### Techniques de visualisation

1. **Deconvolutional Network (deconvnet)** : Utilisée pour projeter les activations des caractéristiques intermédiaires vers l'espace des pixels d'entrée, cette technique aide à comprendre quelles entrées stimulent une carte de caractéristiques particulière.
2. **Analyse de sensibilité** : En occultant des portions de l'image d'entrée, cette technique révèle quelles parties de la scène sont importantes pour la classification.

### Contributions de l'étude

1. **Architecture de modèle** : Les visualisations ont permis de découvrir des architectures de modèles surpassant les résultats de Krizhevsky et al. sur ImageNet.
2. **Étude d'ablation** : Cette étude a permis de déterminer la contribution des différentes couches du modèle aux performances globales.
3. **Généralisation des modèles** : Le modèle entraîné sur ImageNet a montré une bonne généralisation à d'autres jeux de données, comme Caltech-101 et Caltech-256.

### Approche méthodologique

Les modèles convnet supervisés sont utilisés pour mapper une image 2D en couleur vers un vecteur de probabilité sur différentes classes. Les couches comprennent des convolutions avec des filtres appris, des fonctions rectifiées linéaires (ReLU), des opérations de pooling maximum et des opérations de normalisation locale.

### Visualisation avec un Deconvnet

Pour comprendre le fonctionnement d'un convnet, les auteurs utilisent un deconvnet pour mapper les activités des caractéristiques intermédiaires vers l'espace des pixels d'entrée. Cela aide à montrer quels motifs d'entrée ont causé une activation donnée dans les cartes de caractéristiques. Le processus comprend les étapes suivantes :

1. **Unpooling** : Inverse approximative de l'opération de pooling maximum.
2. **Rectification** : Utilisation des non-linéarités ReLU pour obtenir des reconstructions valides des caractéristiques.
3. **Filtrage** : Utilisation des filtres transposés des couches convolutionnelles pour inverser les convolutions.

### Résultats expérimentaux

1. **ImageNet 2012** : L'architecture proposée a surpassé celle de Krizhevsky et al., avec une amélioration significative des taux d'erreur.
2. **Généralisation des caractéristiques** : Les caractéristiques extraites d'ImageNet ont permis d'obtenir des résultats de pointe sur les jeux de données Caltech-101 et Caltech-256.
3. **Sensibilité à l'occultation** : Les expériences ont montré que le modèle est sensible aux structures locales des images et qu'il ne se contente pas d'utiliser le contexte de la scène pour la classification.

### Conclusion

L'étude montre que les visualisations permettent de mieux comprendre le fonctionnement des convnets et d'améliorer leurs performances. En plus, les modèles entraînés sur ImageNet montrent une bonne capacité de généralisation à d'autres jeux de données visuels. Ces techniques de visualisation et d'analyse sont des outils précieux pour le développement et l'amélioration des architectures de réseaux de neurones convolutionnels.

