# Table des Mati√®res

1. [Formule 1: Z-Score](#formule-1)
2. [Formule 2: Intervalle Interquartile (IQR)](#formule-2)
3. [Formule 3: Distance Euclidienne](#formule-3)
4. [Formule 4: Distance de Manhattan](#formule-4)
5. [Formule 5: Distance de Mahalanobis](#formule-5)
6. [Section 1: Introduction √† la d√©tection d'anomalies](#section-1)
7. [Section 2: Comprendre les anomalies](#section-2)
8. [Section 3: Exercice Pratique](#section-3)
9. [Section 4: D√©tection des Outliers](#section-4)
10. [Section 5: Algorithmes Non Bas√©s sur le Clustering](#section-5)
11. [Section 6: Explication des R√©sultats de la D√©tection d'Anomalies dans un Contexte de Fraude](#section-6)
12. [Section 7: Comparaison des Algorithmes de D√©tection d'Anomalies avec PyOD](#section-7)

---

# FORMULES 

---

## Formule 1: Z-Score
<a name="formule-1"></a>

$$
Z = \frac{(X - \mu)}{\sigma}
$$
  
  o√π \(Z\) est le Z-score, \(X\) est la valeur du point de donn√©es, \(\mu\) est la moyenne de l'ensemble de donn√©es, et \(\sigma\) est l'√©cart-type.

[Retour en haut](#table-des-mati√®res)

---

## Formule 2: Intervalle Interquartile (IQR)
<a name="formule-2"></a>

$$
IQR = Q3 - Q1
$$

 o√π \(Q3\) est le troisi√®me quartile (75e percentile) et \(Q1\) est le premier quartile (25e percentile).

[Retour en haut](#table-des-mati√®res)
 
---

## Formule 3: Distance Euclidienne
<a name="formule-3"></a>

$$
d = \sqrt{\sum_{i=1}^{n}(X_i - Y_i)^2}
$$

  o√π \(d\) est la distance Euclidienne entre les points \(X\) et \(Y\).

[Retour en haut](#table-des-mati√®res)

---

## Formule 4: Distance de Manhattan
<a name="formule-4"></a>

$$
d = \sum_{i=1}^{n} |X_i - Y_i|
$$

o√π \(d\) est la distance de Manhattan entre les points \(X\) et \(Y\).

[Retour en haut](#table-des-mati√®res)

---

## Formule 5: Distance de Mahalanobis
<a name="formule-5"></a>

$$
d_M = \sqrt{(X - \mu)^T \Sigma^{-1} (X - \mu)}
$$

$$ 
\mu
$$ 

est le vecteur de la moyenne.

$$
\Sigma
$$

est la matrice de covariance.

[Retour en haut](#table-des-mati√®res)

---

# Section 1: Introduction √† la d√©tection d'anomalies
<a name="section-1"></a>

- La d√©tection d'anomalies est un domaine de plus en plus adopt√© dans l'industrie.
- Au c≈ìur de ce concept, une anomalie est quelque chose qui ne correspond pas au reste des donn√©es ou des transactions.
- Ce principe est largement applicable dans diff√©rents secteurs, tels que l'industrie manufacturi√®re sous forme de maintenance pr√©dictive, ainsi que dans la d√©tection de fraudes.
- Cette pr√©sentation commence par une compr√©hension des anomalies et des diff√©rents types d'anomalies.
- La pr√©sentation est structur√©e pour introduire les trois types de d√©tection d'anomalies et les domaines d'application associ√©s.
- Nous aborderons ensuite le codage pertinent pour les types de d√©tection en apprentissage non supervis√©.
- Les donn√©es et les codes utilis√©s dans cette pr√©sentation sont disponibles dans le dossier ressources, vous permettant ainsi de les t√©l√©charger et de pratiquer en m√™me temps, dans la deuxi√®me partie de la s√©ance.

[Retour en haut](#table-des-mati√®res)

---

# Section 2: Comprendre les anomalies
<a name="section-2"></a>

- Avant de plonger dans les algorithmes, il est essentiel de comprendre ce que sont les anomalies.
- Une anomalie peut √™tre un ou plusieurs points de donn√©es qui ne s'int√®grent pas au reste des donn√©es.
- Identifier des anomalies dans un petit ensemble de donn√©es est g√©n√©ralement facile, mais cela devient difficile avec des ensembles de donn√©es **plus volumineux**.
- Il existe trois types principaux d'anomalies :
  - **Anomalies bas√©es sur le temps** : Les points de donn√©es sont d√©pendants du temps. Par exemple, le prix de l'essence √† diff√©rents jours d'un mois.
  - **Anomalies non bas√©es sur le temps** : Les points de donn√©es ne sont pas d√©pendants du temps. Par exemple, le prix d'un appartement dans une ville donn√©e en fonction de plusieurs facteurs.
  - **Anomalies d'image** : D√©tecter des anomalies dans un ensemble d'images, comme pour les donn√©es classiques.
- Les anomalies peuvent √™tre d√©tect√©es √† l'aide d'algorithmes supervis√©s ou non supervis√©s :
  - **Supervis√©** : Lorsque des r√©f√©rences pass√©es d'anomalies sont disponibles.
  - **Non supervis√©** : Lorsque ces r√©f√©rences ne sont pas disponibles, ce qui est souvent le cas en entreprise.
- Les algorithmes non supervis√©s sont souvent pr√©f√©r√©s en raison de l'absence de donn√©es robustes. Ils peuvent √™tre bas√©s sur des clusters ou non.
- Exemples de jeux de donn√©es :
  - **Jeux de donn√©es bas√©s sur le temps** : Par exemple, les transactions d'un client bancaire √† diff√©rents moments.
  - **Jeux de donn√©es non bas√©s sur le temps** : Par exemple, le prix d'un appartement en fonction de diff√©rents facteurs sans r√©f√©rence au temps.
- La d√©tection d'anomalies bas√©e sur le temps est particuli√®rement utile pour identifier des √©v√©nements rares mais critiques, comme la maintenance pr√©dictive dans l'industrie.
- **Concept d'outliers (valeurs aberrantes)** :
  - Les outliers sont des points de donn√©es extr√™mes.
  - Chaque outlier est une anomalie, mais toutes les anomalies ne sont pas des outliers (voir la discussion dans l'**annexe 1**).
  - Techniques de d√©tection des outliers :
    - **Box plot** : Utilisation de l'intervalle interquartile.
    - **Diagramme de contr√¥le** : Utilisation de la moyenne et de l'√©cart-type pour d√©finir des limites de contr√¥le.
- En r√©sum√©, bien que chaque outlier soit une anomalie, l'inverse n'est pas toujours vrai.

[Retour en haut](#table-des-mati√®res)

---

# Section 3: Exercice Pratique
<a name="section-3"></a>

**Instructions de l'exercice**

- Temps allou√© : 30 minutes

- Dans cet exercice, vous √™tes invit√©s √† fournir des exemples d'application des anomalies et de la d√©tection d'anomalies dans la vie r√©elle (Apr√®s, vous pouvez consulter le document 02-exemples-d-applications-.. dans le m√™me dossier ici). 
- Cet exercice vous aidera dans votre parcours d'apprentissage, car vous pouvez de vous r√©f√©rer √† ces exemples tout au long de ce cours et aussi √©valuer l'importance de la d√©tection d'anomalies dans des situations r√©elles.

**Questions pour cet exercice :**

1. D√©crivez ce qu'est une anomalie avec vos propres mots.
2. Donnez des exemples d'anomalies bas√©es sur le temps. Les exemples peuvent provenir de votre domaine professionnel ou d'un domaine que vous connaissez bien.
3. Donnez des exemples d'anomalies non bas√©es sur le temps (non supervis√©es). Les exemples peuvent provenir de votre domaine professionnel ou d'un domaine que vous connaissez bien.
4. Donnez des exemples d'anomalies non bas√©es sur le temps (supervis√©es). Les exemples peuvent provenir de votre domaine professionnel ou d'un domaine que vous connaissez bien.
5. Donnez des exemples d'anomalies bas√©es sur les images. Les exemples peuvent provenir de votre domaine professionnel ou d'un domaine que vous connaissez bien.

[Retour en haut](#table-des-mati√®res)

---

**Proposition de l'instructeur :**

1. **D√©crivez ce qu'est une anomalie avec vos propres mots.**
   - Une anomalie est un point de donn√©es qui ne correspond pas ou ne s'int√®gre pas bien avec les autres points de donn√©es.

2. **Donnez des exemples d'anomalies bas√©es sur le temps.**
   - <Il s'agit d'une question bas√©e sur l'application des concepts. Il n'y a donc pas de r√©ponse standard. Les apprenants doivent r√©pondre en fonction de leur compr√©hension.>

3. **Donnez des exemples d'anomalies non bas√©es sur le temps (non supervis√©es).**
   - <Il s'agit d'une question bas√©e sur l'application des concepts. Il n'y a donc pas de r√©ponse standard. Les apprenants doivent r√©pondre en fonction de leur compr√©hension.>

4. **Donnez des exemples d'anomalies non bas√©es sur le temps (supervis√©es).**
   - <Il s'agit d'une question bas√©e sur l'application des concepts. Il n'y a donc pas de r√©ponse standard. Les apprenants doivent r√©pondre en fonction de

 leur compr√©hension.>

5. **Donnez des exemples d'anomalies bas√©es sur les images.**
   - <Il s'agit d'une question bas√©e sur l'application des concepts. Il n'y a donc pas de r√©ponse standard. Les apprenants doivent r√©pondre en fonction de leur compr√©hension.>

[Retour en haut](#table-des-mati√®res)

---

# Section 4:

----

# Section 4.1 : D√©tection des Outliers
<a name="section-4"></a>

- Dans cette section, nous allons explorer diff√©rentes m√©thodes pour d√©tecter les outliers, c'est-√†-dire des points de donn√©es extr√™mes qui se situent nettement en dehors de la majorit√© d'un ensemble de donn√©es ou d'un cluster. La d√©tection des outliers est cruciale pour une analyse statistique pr√©cise et la performance des mod√®les.

## M√©thode du Z-Score

- La m√©thode du Z-score est une technique statistique utilis√©e pour identifier les outliers en mesurant le nombre d'√©carts-types d'un point de donn√©es par rapport √† la moyenne de l'ensemble de donn√©es.

# Voir FORMULE 1

- **Interpr√©tation :** Les points de donn√©es avec un Z-score sup√©rieur √† 3 ou inf√©rieur √† -3 sont consid√©r√©s comme des outliers car ils se situent bien en dehors de la plage normale des donn√©es. Parfois, une valeur seuil de 2 au lieu de 3 est √©galement utilis√©e.

- **Exemple :** Prenons un ensemble de donn√©es comprenant des identifiants de factures et leurs montants respectifs. En calculant le Z-score pour chaque montant, les valeurs avec un Z-score sup√©rieur √† 3 ou inf√©rieur √† -3 sont marqu√©es comme outliers.

- **Programmation :** En Python, cela peut √™tre accompli en utilisant les biblioth√®ques `numpy` et `pandas`. Vous calculez d'abord la moyenne et l'√©cart-type, puis vous appliquez la formule du Z-score pour chaque point de donn√©es.

## M√©thode de l'Intervalle Interquartile (IQR)

- La m√©thode de l'Intervalle Interquartile (IQR) identifie les outliers en mesurant l'√©tendue des 50 % de donn√©es centrales. L'IQR est calcul√© comme la diff√©rence entre le troisi√®me quartile (\(Q3\)) et le premier quartile (\(Q1\)).

# Voir FORMULE 2

- **Interpr√©tation :** Les valeurs situ√©es en dessous de \(Q1 - 1.5 \times IQR\) ou au-dessus de \(Q3 + 1.5 \times IQR\) sont consid√©r√©es comme des outliers.

- **Exemple :** Dans notre ensemble de donn√©es de factures, les montants situ√©s en dehors de ces bornes (par exemple, en dessous de 77.5 ou au-dessus de 105.5) sont identifi√©s comme des outliers.

- **Programmation :** Vous pouvez calculer les quantiles avec la m√©thode `quantile()` de `pandas`, puis identifier les outliers en appliquant la formule de l'IQR.


## Annexe pour IQR pour celles et ceux qui ont des difficult√©s en math√©matiques: 

- L'Intervalle Interquartile (IQR) est une mesure de dispersion statistique qui montre l'√©cart entre les valeurs du premier quartile (Q1) et du troisi√®me quartile (Q3). Pour l'expliquer √† quelqu'un qui ne comprend pas bien les statistiques, on peut utiliser une analogie simple.

- Imagine que tu as un groupe d'enfants dans une cour de r√©cr√©ation. Chaque enfant a un jouet, et tu veux savoir si la plupart des enfants ont des jouets similaires en taille. Si on classe tous les jouets du plus petit au plus grand, le quartile 1 (Q1) repr√©sente la taille en dessous de laquelle se trouve le premier quart des jouets les plus petits. Le quartile 3 (Q3) repr√©sente la taille en dessous de laquelle se trouve les trois quarts des jouets, c'est-√†-dire que seuls les plus grands jouets sont au-dessus de cette taille.

- L'IQR, ou l'Intervalle Interquartile, est simplement la diff√©rence entre la taille du jouet au niveau de Q3 et celle au niveau de Q1. Cela te donne une id√©e de la taille moyenne des jouets qui ne sont ni trop petits ni trop grands, c'est-√†-dire des jouets qui se situent au milieu de la distribution. Si cet intervalle est petit, √ßa veut dire que la plupart des jouets sont de tailles similaires. S'il est grand, √ßa signifie qu'il y a une grande variation de taille entre les jouets.

- Dans la vraie vie, l'IQR peut √™tre utilis√© pour √©valuer la "consistance" des donn√©es. Par exemple, si tu regardes les notes des √©l√®ves dans une classe, l'IQR te dirait √† quel point les notes de la majorit√© des √©l√®ves sont proches les unes des autres, en √©liminant les notes les plus extr√™mes (les plus basses et les plus hautes).


- Simplifions encore :

- Imagine que tu as 100 biscuits de tailles diff√©rentes, que tu veux comparer. Tu les alignes du plus petit au plus grand. Le premier quart (les 25 premiers biscuits) repr√©sente les biscuits petits, et le troisi√®me quart (les 25 derniers avant les plus grands) repr√©sente les biscuits moyens-grands.

- L'Intervalle Interquartile (IQR) te dit simplement de prendre la taille du 75√®me biscuit (Q3) et de soustraire la taille du 25√®me biscuit (Q1). Cela te donne une id√©e de la taille des biscuits qui se trouvent au milieu de ton rang, sans tenir compte des tr√®s petits ou des tr√®s grands.

- En gros, √ßa te montre √† quel point les biscuits du milieu sont de tailles similaires. Si cet intervalle est petit, √ßa veut dire qu'ils sont presque tous de la m√™me taille. S'il est grand, √ßa veut dire qu'ils varient beaucoup en taille.



## M√©thode Bas√©e sur la Distance

La m√©thode bas√©e sur la distance identifie les outliers en mesurant la distance entre les points de donn√©es et la moyenne de l'ensemble de donn√©es. Il existe plusieurs types de distances couramment utilis√©es :

- **Distance Euclidienne :**  

# Voir FORMULE 3

- **Distance de Manhattan :**  

# Voir FORMULE 4

- **Distance de Mahalanobis :**  

# Voir FORMULE 5

- **Exemple :** Dans l'ensemble de donn√©es de factures, vous pouvez utiliser ces diff√©rentes distances pour identifier les points de donn√©es qui sont significativement √©loign√©s de la moyenne, et donc les marquer comme outliers.

- **Programmation :** Utilisez `scipy.spatial.distance` pour calculer ces distances en Python.

## M√©thode DBSCAN

DBSCAN (Density-Based Spatial Clustering of Applications with Noise) est un algorithme de clustering qui regroupe les points de donn√©es proches tout en identifiant les points dans les r√©gions √† faible densit√© comme des outliers.

- **Param√®tres :** L'algorithme n√©cessite deux param√®tres :
  - \(\epsilon\) : la distance maximale pour qu'un point soit consid√©r√© comme voisin d'un autre.
  - \(minPts\) : le nombre minimal de points requis pour former une r√©gion dense.

- **Types de points :**
  - **Point de c≈ìur :** Un point avec au moins \(minPts\) voisins dans son voisinage d√©fini par \(\epsilon\).
  - **Point de bordure :** Un point dans le voisinage d'un point de c≈ìur mais avec moins de \(minPts\) voisins.
  - **Point de bruit :** Un point qui n'est ni un point de c≈ìur ni un point de bordure, et qui est donc consid√©r√© comme un outlier.

- **Exemple :** En appliquant DBSCAN √† un ensemble de donn√©es de factures, les montants isol√©s peuvent √™tre identifi√©s comme des outliers en fonction de leur densit√© locale.

- **Programmation :** Utilisez `DBSCAN` de `scikit-learn` pour appliquer cet algorithme √† vos donn√©es.

----

# Section 4.2 - Exercice 

### Instructions de l'exercice
- D'abord. il faut t√©l√©charger le fichier excel dans le dossier ressources TAT.xlsx: 
1. **Z-Score Method :** D√©terminez le nombre d'outliers en utilisant cette m√©thode.
2. **IQR Method :** Utilisez la m√©thode de l'IQR pour identifier les outliers.
3. **Distance Method :** Appliquez les distances Euclidienne, Manhattan et Mahalanobis pour d√©tecter les outliers.
4. **DBSCAN :** Ajustez les param√®tres \(\epsilon\) et \(minPts\) pour identifier les outliers et observez les r√©sultats.

- Le "Turn Around Time" (TAT) est un terme couramment utilis√© dans divers contextes, notamment en gestion de projet, en op√©rations et en informatique. Il se r√©f√®re g√©n√©ralement au temps total n√©cessaire pour accomplir une t√¢che ou un processus du d√©but √† la fin. 
- Exemples:
  
1. **Gestion de projet/Op√©rations** : Le "Turn Around Time" d√©signe le temps total √©coul√© entre l'initiation d'une t√¢che ou d'un processus et son ach√®vement. Par exemple, le temps √©coul√© entre le moment o√π un client passe une commande et celui o√π la commande est ex√©cut√©e et livr√©e.

2. **Fabrication** : Le "Turn Around Time" peut faire r√©f√©rence au temps n√©cessaire pour passer d'une production √† une autre sur une machine ou une ligne de production. Cela peut aussi indiquer le temps requis pour r√©parer ou entretenir un √©quipement.

3. **Soins de sant√©** : Dans le domaine de la sant√©, le "Turn Around Time" peut d√©signer le temps pris pour effectuer des tests m√©dicaux et fournir les r√©sultats au patient ou au professionnel de sant√©.

4. **Informatique/Ing√©nierie logicielle** : En informatique, le "Turn Around Time" peut d√©signer le temps total pris par un syst√®me informatique pour ex√©cuter une t√¢che ou un processus depuis le moment o√π il est soumis jusqu'√† ce que les r√©sultats soient disponibles.

[Retour en haut](#table-des-mati√®res)

----

# Section 4.3 - proposition de correction pour la d√©tection des Outliers

```python
# Importer les biblioth√®ques n√©cessaires
import pandas as pd
import numpy as np
from scipy.spatial import distance
from scipy.stats import zscore
from sklearn.covariance import EmpiricalCovariance
from sklearn.cluster import DBSCAN

# Charger les donn√©es √† partir d'un fichier CSV
data = pd.read_csv('chemin_du_fichier.csv')

# Extraire la colonne 'Turn Around Time' (temps de rotation) pour l'analyse
tat = data['Turn Around Time']

# M√©thode 1 : Z-Score
# Le Z-Score est utilis√© pour normaliser les donn√©es et identifier les valeurs qui s'√©cartent 
# de la moyenne par plus de 3 √©carts-types
data['z_score'] = zscore(tat)
z_outliers = data[np.abs(data['z_score']) > 3]  # Les outliers sont ceux avec un Z-Score absolu > 3

# M√©thode 2 : IQR (Interquartile Range)
# Le IQR est la diff√©rence entre le troisi√®me quartile (Q3) et le premier quartile (Q1)
# Cette m√©thode identifie les outliers en dehors de l'intervalle [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
Q1 = tat.quantile(0.25)
Q3 = tat.quantile(0.75)
IQR = Q3 - Q1
iqr_outliers = data[(tat < (Q1 - 1.5 * IQR)) | (tat > (Q3 + 1.5 * IQR))]

# M√©thode 3 : M√©thode des distances
# Utilisation de trois types de distances pour identifier les outliers

# Calculer le vecteur moyen pour la distance
mean_vector = np.mean(tat)

# Calculer la matrice de covariance pour la distance de Mahalanobis
cov_matrix = np.cov(tat)
inv_cov_matrix = np.linalg.inv(cov_matrix.reshape(1, 1))

# 3.1) Distance de Manhattan
# Calcul de la distance de Manhattan pour chaque point et identification des outliers
manhattan_outliers = data[distance.cdist(tat.values.reshape(-1, 1), np.array([[mean_vector]]), 'cityblock').flatten() > 3]

# 3.2) Distance Euclidienne
# Calcul de la distance Euclidienne pour chaque point et identification des outliers
euclidean_outliers = data[distance.cdist(tat.values.reshape(-1, 1), np.array([[mean_vector]]), 'euclidean').flatten() > 3]

# 3.3) Distance de Mahalanobis
# Calcul de la distance de Mahalanobis pour chaque point et identification des outliers
mahalanobis_outliers = data[distance.cdist(tat.values.reshape(-1, 1), np.array([[mean_vector]]), 'mahalanobis', VI=inv_cov_matrix).flatten() > 3]

# M√©thode 4 : DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
# DBSCAN est un algorithme de clustering qui peut identifier les points aberrants comme ceux qui ne font pas partie d'un cluster dense
dbscan = DBSCAN(eps=0.5, min_samples=5).fit(tat.values.reshape(-1, 1))
data['dbscan_labels'] = dbscan.labels_
dbscan_outliers = data[data['dbscan_labels'] == -1]  # Les outliers sont √©tiquet√©s avec -1 par DBSCAN

# Compter et afficher le nombre d'outliers d√©tect√©s par chaque m√©thode
outlier_counts = {
    "Z-Score": len(z_outliers),
    "IQR": len(iqr_outliers),
    "Manhattan Distance": len(manhattan_outliers),
    "Euclidean Distance": len(euclidean_outliers),
    "Mahalanobis Distance": len(mahalanobis_outliers),
    "DBSCAN": len(dbscan_outliers)
}

print("Nombre d'outliers d√©tect√©s par chaque m√©thode :")
for method, count in outlier_counts.items():
    print(f"{method}: {count}")
```

### Explications :

1. **D√©termination du nombre d'outliers en utilisant diff√©rentes m√©thodes** :
   - **M√©thode Z-Score** : Normalisation des donn√©es pour identifier les points qui s'√©cartent significativement de la moyenne.
   - **M√©thode IQR (Interquartile Range)** : Utilisation des quartiles pour d√©finir un intervalle de valeurs "normales" et identifier les valeurs extr√™mes.
   - **M√©thode des distances** : Application de trois distances diff√©rentes (Manhattan, Euclidienne, Mahalanobis) pour identifier les outliers bas√©s sur la distance par rapport √† un centre.
   - **DBSCAN** : Algorithme de clustering qui identifie les outliers en tant que points isol√©s ne faisant partie d'aucun cluster dense.

2. **Modification des param√®tres de DBSCAN pour ajuster la d√©tection des outliers** :
   - Test de diff√©rentes valeurs pour epsilon (la distance maximale entre deux points pour √™tre consid√©r√©s voisins) et `min_samples` (le nombre minimum de points pour former un cluster).

3. **Optimisation du seuil pour la m√©thode du Z-Score** :
   - Exploration de plusieurs seuils (de 3 √† 1) pour identifier celui qui capture le plus grand nombre d'outliers. 


---

# Section 5 : Algorithmes Non Bas√©s sur le Clustering
<a name="section-5"></a>

## Introduction

Dans la session pr√©c√©dente, nous avons explor√© les algorithmes de clustering pour la d√©tection des anomalies. Dans cette section, nous allons nous concentrer sur les algorithmes non bas√©s sur le clustering, qui d√©tectent les anomalies en √©valuant chaque point de donn√©es individuellement ou dans des contextes localis√©s, sans former de clusters globaux.

## Diff√©rences entre Algorithmes de Clustering et Non Clustering

- **Algorithmes de Clustering :** Ils regroupent les points de donn√©es en clusters bas√©s sur la similarit√©. Les anomalies sont identifi√©es comme des points qui d√©vient de mani√®re significative de ces clusters. Les m√©thodes incluent K-means, DBSCAN, les mod√®les de m√©langes gaussiens (GMM), et le clustering hi√©rarchique.

- **Algorithmes Non Clustering :** Ils √©valuent chaque point de donn√©es individuellement, en se basant sur des propri√©t√©s statistiques ou de densit√© locales. Les anomalies sont d√©tect√©es en fonction de leur d√©viation par rapport au comportement attendu. Les algorithmes incluent Isolation Forest, One-Class SVM, et Local Outlier Factor (LOF).

## Isolation Forest

**Isolation Forest** est un algorithme non bas√© sur le clustering qui isole les anomalies en partitionnant les donn√©es de mani√®re r√©cursive. Les anomalies sont rapidement isol√©es avec un nombre minimal de divisions car elles se trouvent dans des r√©gions peu denses de l'espace des donn√©es.

### Fonctionnement de l'algorithme

1. **Partitionnement Al√©atoire :** L'algorithme commence par diviser les donn√©es de mani√®re al√©atoire sur une caract√©ristique donn√©e.
2. **Isolation des Anomalies :** Les points isol√©s rapidement avec moins de divisions sont consid√©r√©s comme des anomalies.
3. **Longueur du Chemin :** La longueur du chemin pour isoler un point est utilis√©e pour d√©terminer s'il est une anomalie. Une longueur de chemin courte indique une anomalie.

### Exemple

Prenons un petit ensemble de donn√©es avec deux caract√©ristiques. Isolation Forest partitionne les donn√©es et isole les points en fonction de leur position relative par rapport aux autres. Les points qui n√©cessitent moins de divisions pour √™tre isol√©s sont consid√©r√©s comme des anomalies.

### Programmation

En Python, vous pouvez utiliser `IsolationForest` de la biblioth√®que `sklearn` pour impl√©menter cet algorithme. Voici un exemple de code :

```python
from sklearn.ensemble import IsolationForest

# Application de Isolation Forest
iso_forest = IsolationForest(contamination=0.05, random_state=42)
iso_forest.fit(X)
anomalies = iso_forest.predict(X)
```

## Histogram-Based Outlier Score (HBOS)

**HBOS** est un algorithme efficace pour la d√©tection des anomalies bas√© sur les histogrammes des distributions des caract√©ristiques. Il construit des histogrammes pour chaque caract√©ristique, et les anomalies sont identifi√©es en fonction de leur densit√© dans ces histogrammes.

### Fonctionnement de l'algorithme

1. **Construction des Histogrammes :** Pour chaque caract√©ristique, un histogramme est construit.
2. **Densit√© de Probabilit√© :** La densit√© de probabilit√© est calcul√©e pour chaque point de donn√©es. Les points dans des bacs √† faible fr√©quence sont consid√©r√©s comme des anomalies.
3. **Score d'Anomalie :** Les scores sont combin√©s pour obtenir un score global d'anomalie pour chaque point de donn√©es.

### Programmation

Voici un exemple de code pour appliquer HBOS √† un ensemble de donn√©es en utilisant Python :

```python
from pyod.models.hbos import HBOS

# Application de HBOS
hbos = HBOS()
hbos.fit(X)
anomaly_scores = hbos.decision_function(X)
anomalies = hbos.predict(X)
```

## Approche Hybride

Une approche hybride combine

 les avantages des algorithmes de clustering et des algorithmes non clustering pour am√©liorer la pr√©cision de la d√©tection des anomalies. Par exemple, vous pouvez utiliser **GMM** pour identifier les anomalies globales et **LOF** pour d√©tecter les anomalies locales au sein de ces clusters.

### Exemple d'Impl√©mentation Hybride

En appliquant GMM pour cr√©er des clusters, puis en appliquant LOF √† chaque cluster, vous pouvez identifier un plus large √©ventail d'anomalies, y compris celles qui pourraient √™tre ignor√©es par une seule m√©thode.

```python
from sklearn.mixture import GaussianMixture
from sklearn.neighbors import LocalOutlierFactor

# Application de GMM pour le clustering
gmm = GaussianMixture(n_components=3)
gmm_labels = gmm.fit_predict(X)

# Application de LOF √† chaque cluster
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)
lof_anomalies = lof.fit_predict(X[gmm_labels == 0])
```

## Exercice Pratique

### Instructions de l'Exercice

1. **D√©tection Initiale des Anomalies :** Utilisez l'algorithme Isolation Forest avec un taux de contamination de 5 % pour identifier un premier ensemble d'anomalies.
2. **Raffinement des Anomalies :** Parmi les anomalies identifi√©es, isolez celles qui se situent dans les percentiles 90 et 95, en fonction de leur distance par rapport √† la moyenne de l'ensemble des donn√©es.
3. **Visualisation :** R√©duisez la dimensionnalit√© des donn√©es avec PCA et visualisez les anomalies.

ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶ü´¶
‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è
# EXERCICE (06-Exercice 3 - non clustering)
- exemple de code pour cet exercice :

```python
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Chargement des donn√©es
data = pd.read_csv('votre_fichier.csv')

# D√©tection initiale des anomalies
iso_forest = IsolationForest(contamination=0.05)
anomalies = iso_forest.fit_predict(data)

# Raffinement des anomalies
pca = PCA(n_components=2)
data_reduced = pca.fit_transform(data)
plt.scatter(data_reduced[:, 0], data_reduced[:, 1], c=anomalies)
plt.show()
```

[Retour en haut](#table-des-mati√®res)

---

# Section 6 : Explication des R√©sultats de la D√©tection d'Anomalies dans un Contexte de Fraude
<a name="section-6"></a>

#### Contexte : D√©tection de Fraude dans l'Assurance Automobile

Dans cette section, nous allons approfondir la mani√®re d'expliquer les r√©sultats d'un algorithme de d√©tection d'anomalies, en prenant pour exemple un sc√©nario de d√©tection de fraude dans le secteur de l'assurance automobile. Ce domaine est particuli√®rement sensible, car la d√©tection d'anomalies y signifie potentiellement l'identification de comportements frauduleux de la part des clients, des partenaires, ou m√™me des employ√©s.

Le type d'analyse que nous r√©alisons est un apprentissage non supervis√©, c'est-√†-dire que nous n'avons pas de donn√©es labellis√©es indiquant quels cas sont des fraudes. Cela rend l'explication des r√©sultats encore plus cruciale, car nous devons convaincre les parties prenantes que les anomalies identifi√©es par notre mod√®le sont dignes d'une investigation plus pouss√©e.

#### Importance de l'Explication des Anomalies

Lorsque nous pr√©sentons les r√©sultats d'un mod√®le de d√©tection d'anomalies √† des clients ou √† la direction, la question qui revient souvent est : *"Comment pouvez-vous affirmer que ces cas sont des anomalies ?"*. Cette question est encore plus pertinente dans le cadre de la d√©tection de fraude, car signaler une anomalie peut √™tre per√ßu comme une accusation directe de malversation. Pour √©viter toute incompr√©hension ou m√©fiance, il est imp√©ratif de pouvoir fournir une explication claire et d√©taill√©e des raisons pour lesquelles un point de donn√©es sp√©cifique est consid√©r√© comme une anomalie.

Dans un contexte de d√©tection de fraude, il est important de faire preuve de diplomatie. Par exemple, au lieu de dire directement que certaines transactions sont frauduleuses, nous pouvons les d√©crire comme des "cas potentiellement non conformes" qui n√©cessitent une enqu√™te plus approfondie. Toutefois, m√™me en adoucissant le message, l'essentiel reste que nous pointons du doigt des transactions suspectes, ce qui implique que certaines personnes ou organisations pourraient √™tre suspect√©es de fraude.

#### Utilit√© des Algorithmes d'Explication : SHAP

Expliquer pourquoi un algorithme d√©tecte certaines anomalies est essentiel, surtout dans un contexte o√π les r√©sultats du mod√®le peuvent avoir des cons√©quences significatives sur les op√©rations d'une entreprise. C'est l√† qu'intervient SHAP (SHapley Additive exPlanations), un algorithme d'explication qui permet de d√©composer les d√©cisions de mod√®les complexes, comme les mod√®les de for√™ts d'isolement (Isolation Forest), pour montrer comment chaque facteur individuel a contribu√© √† l'identification d'une anomalie.

Dans notre sc√©nario, nous analysons 32 facteurs diff√©rents pour identifier des anomalies dans les donn√©es. Le but de SHAP est de nous aider √† isoler les facteurs critiques qui ont conduit √† l'identification de ces anomalies. Ce type d'information est extr√™mement pr√©cieux non seulement pour justifier pourquoi certaines transactions sont suspectes, mais aussi pour aider √† mettre en place des contr√¥les pr√©ventifs visant √† minimiser les risques de fraude √† l'avenir.

#### Construction du Mod√®le : Isolation Forest

La premi√®re √©tape consiste √† construire un mod√®le Isolation Forest pour identifier les anomalies dans notre jeu de donn√©es. Isolation Forest est un algorithme qui fonctionne en isolant les anomalies en se basant sur la distance qui les s√©pare des autres points de donn√©es. Plus un point est isol√© rapidement, plus il est susceptible d'√™tre une anomalie.

**√âtape 1 : Importation des Biblioth√®ques et Chargement des Donn√©es**

Nous commen√ßons par importer les biblioth√®ques n√©cessaires, y compris SHAP pour l'explication des anomalies, et pandas pour la manipulation des donn√©es.

```python
import shap
import pandas as pd
from sklearn.ensemble import IsolationForest

# Chargement du jeu de donn√©es
data = pd.read_csv('chemin_vers_le_fichier.csv')
```

**√âtape 2 : Construction du Mod√®le Isolation Forest**

Ensuite, nous construisons le mod√®le Isolation Forest en d√©finissant le param√®tre de contamination √† 1 %. Cela signifie que nous demandons √† l'algorithme de d√©tecter au moins 1 % des points de donn√©es comme des anomalies. Le mod√®le est ensuite ajust√© (fit) aux donn√©es.

```python
# Construction du mod√®le Isolation Forest
iso_forest = IsolationForest(contamination=0.01, random_state=42)
iso_forest.fit(data)
```

#### Explication des Anomalies avec SHAP

Une fois le mod√®le Isolation Forest en place, nous utilisons SHAP pour expliquer pourquoi certains points de donn√©es ont √©t√© identifi√©s comme des anomalies. SHAP attribue une valeur √† chaque facteur, ce qui permet de voir l'importance relative de chaque facteur dans la d√©cision d'isoler un point de donn√©es comme anomalie.

**√âtape 3 : Utilisation de SHAP pour Expliquer les Anomalies**

SHAP nous permet d'analyser chaque point d'anomalie individuellement et de comprendre quels facteurs sp√©cifiques ont contribu√© √† son identification.

```python
# Utilisation de SHAP pour expliquer les anomalies
explainer = shap.Explainer(iso_forest, data)
shap_values = explainer(data)

# Boucle sur chaque anomalie pour afficher les facteurs contributifs
for i in range(len(data)):
    shap.force_plot(explainer.expected_value, shap_values[i], data.iloc[i])
```

- Dans cette analyse, les facteurs marqu√©s en rouge sont ceux qui ont un impact positif significatif sur la d√©tection de l'anomalie, tandis que ceux en bleu ont un impact n√©gatif ou n√©gligeable. Par exemple, si un point de donn√©es pr√©sente une anomalie due √† une combinaison sp√©cifique de type de collecte et de fabrication automatique, ces facteurs appara√Ætront en rouge, signalant leur importance.

#### Identification des Facteurs Critiques √† l'√âchelle Globale

Au-del√† de l'explication des anomalies individuelles, SHAP peut √©galement √™tre utilis√© pour identifier les principaux facteurs contribuant aux anomalies dans l'ensemble du jeu de donn√©es. Cela est essentiel pour les √©quipes op√©rationnelles, qui peuvent utiliser ces informations pour renforcer les contr√¥les internes et pr√©venir la fraude √† l'avenir.

**√âtape 4 : D√©termination des Facteurs Cl√©s de l'Ensemble des Anomalies**

Pour identifier les principaux facteurs influen√ßant les anomalies, nous calculons la valeur absolue moyenne des contributions SHAP pour chaque facteur, que nous classons ensuite par ordre d√©croissant.

```python
# Identification des facteurs critiques √† l'√©chelle globale
mean_shap_values = np.abs(shap_values.values).mean(axis=0)
important_factors = pd.DataFrame(list(zip(data.columns, mean_shap_values)), columns=['Facteur', 'Importance SHAP'])
important_factors = important_factors.sort_values(by='Importance SHAP', ascending=False)

# Affichage des principaux facteurs
print(important_factors.head(5))
```

En classant les facteurs en fonction de leur importance SHAP, nous pouvons voir quels facteurs, tels que la limite d'assurance, l'√¢ge du client ou la gravit√© de l'incident, ont le plus grand impact sur la d√©tection des anomalies.

#### Application Pratique : Contr√¥les Pr√©ventifs Bas√©s sur SHAP

- Les informations fournies par SHAP ne servent pas seulement √† expliquer les r√©sultats du mod√®le, mais aussi √† √©laborer des strat√©gies pr√©ventives

.
- Par exemple, si l'analyse montre que la limite d'assurance et l'√¢ge du client sont des facteurs critiques pour la fraude, des contr√¥les sp√©cifiques peuvent √™tre mis en place pour surveiller de plus pr√®s ces variables lors de l'√©valuation des nouvelles demandes d'assurance.

### Conclusion de la partie 6

- L'utilisation d'algorithmes d'explication comme SHAP en conjonction avec des mod√®les de d√©tection d'anomalies tels qu'Isolation Forest permet non seulement d'identifier des anomalies, mais aussi de comprendre pourquoi ces anomalies se produisent.
- Cette compr√©hension approfondie est essentielle non seulement pour justifier les d√©cisions de l'algorithme, mais aussi pour mettre en place des mesures de pr√©vention efficaces et ainsi r√©duire les risques de fraude √† l'avenir.

[Retour en haut](#table-des-mati√®res)

---

# Section 7 : Comparaison des Algorithmes de D√©tection d'Anomalies avec la Biblioth√®que PyOD
<a name="section-7"></a>

#### Introduction √† PyOD et Contexte de l'Exercice

- Dans cette section, nous allons explorer l'utilisation de la biblioth√®que **PyOD** (Python Outlier Detection), un outil puissant pour la d√©tection d'anomalies dans les donn√©es multivari√©es.
- PyOD est un ensemble de plus de 30 algorithmes diff√©rents, qui ont √©t√© largement utilis√©s dans la recherche acad√©mique pour d√©tecter des anomalies dans divers types de jeux de donn√©es.

- Pour illustrer l'efficacit√© de PyOD, nous appliquerons plusieurs de ces algorithmes sur un jeu de donn√©es provenant de Kaggle, sp√©cifiquement un jeu de donn√©es sur les assurances sant√©.
- Ce jeu de donn√©es est utilis√© pour pr√©dire la persistance des clients √† payer leurs primes d'assurance. Dans ce contexte, un client qui ne paie pas sa prime est consid√©r√© comme une anomalie.

- Le jeu de donn√©es contient environ 80 000 points de donn√©es et 13 attributs diff√©rents, dont 9 attributs continus et 2 attributs nominaux.
- Ces attributs incluent des informations telles que l'√¢ge, le montant de la prime, le revenu, la r√©gion, le canal de souscription, et d'autres variables pertinentes pour pr√©dire la persistance des paiements.

#### Application des Algorithmes de D√©tection d'Anomalies

Pour cette analyse, nous avons s√©lectionn√© 10 algorithmes de d√©tection d'anomalies diff√©rents, couvrant une vari√©t√© de m√©thodes, notamment :

- **Algorithmes bas√©s sur la proximit√©** : Score d'anomalie bas√© sur la distance, d√©tection bas√©e sur les k plus proches voisins (k-NN), etc.
- **Algorithmes bas√©s sur les for√™ts** : Isolation Forest, un algorithme populaire pour la d√©tection d'anomalies.
- **Algorithmes bas√©s sur les composantes principales** : Analyse en Composantes Principales (PCA).
- **R√©seaux de neurones** : Bien que g√©n√©ralement plus adapt√©s aux donn√©es de type image ou vid√©o, nous appliquons √©galement des mod√®les de deep learning pour observer leur performance sur des donn√©es tabulaires.

Apr√®s avoir appliqu√© ces algorithmes, nous √©valuerons leur performance en termes de pr√©cision, en comparant la d√©tection correcte des anomalies avec les connaissances pr√©alables que nous avons sur les clients qui n'ont pas pay√© leurs primes.

#### Pr√©cision et √âvaluation des Mod√®les

Il est crucial de noter que l'√©valuation de la pr√©cision globale d'un mod√®le peut √™tre trompeuse, surtout dans un contexte de d√©tection d'anomalies. Il est plus pertinent d'√©valuer la pr√©cision s√©par√©ment pour les anomalies et les non-anomalies, car les actions que nous entreprenons en fonction de ces classifications peuvent avoir des impacts significatifs.

Par exemple, si un client est incorrectement identifi√© comme une anomalie (c'est-√†-dire qu'il est identifi√© √† tort comme un client qui ne paiera pas), cela pourrait conduire √† des d√©cisions commerciales erron√©es, comme la r√©siliation pr√©matur√©e d'une police d'assurance ou des actions judiciaires inutiles. Inversement, ne pas identifier une v√©ritable anomalie pourrait laisser passer une fraude ou un risque √©lev√©.

#### Impl√©mentation du Code et R√©sultats

Voici une impl√©mentation d√©taill√©e pour comparer diff√©rents algorithmes de d√©tection d'anomalies en utilisant PyOD :

1. **Pr√©traitement des Donn√©es :**
   - Remplacement des valeurs manquantes par la moyenne (pour les valeurs num√©riques) ou par la modalit√© (pour les valeurs cat√©gorielles).
   - Encodage des variables nominales pour les rendre compatibles avec les algorithmes.
   - Normalisation des donn√©es pour traiter les outliers et pr√©parer les donn√©es pour la mod√©lisation.

2. **Application des Algorithmes :**
   - Importation des algorithmes disponibles dans PyOD.
   - Cr√©ation d'un dictionnaire pour stocker les mod√®les et les r√©sultats.
   - Application de chaque algorithme sur le jeu de donn√©es trait√©.
   - Enregistrement des r√©sultats de chaque mod√®le, incluant la dur√©e d'ex√©cution et la proportion d'anomalies d√©tect√©es.

3. **Analyse des R√©sultats :**
   - Comparaison de la pr√©cision des mod√®les, √† la fois pour les anomalies et les non-anomalies.
   - Visualisation des r√©sultats pour identifier quel algorithme offre la meilleure performance pour ce jeu de donn√©es sp√©cifique.

Voici un extrait de code pour illustrer l'application de PyOD :

```python
# Importation des biblioth√®ques n√©cessaires
import numpy as np
import pandas as pd
from pyod.models.knn import KNN
from pyod.models.iforest import IForest
from sklearn.preprocessing import MinMaxScaler, LabelEncoder

# Chargement et pr√©traitement des donn√©es
data = pd.read_csv('chemin_vers_votre_fichier.csv')
data.fillna(data.mean(), inplace=True)
encoder = LabelEncoder()
data['sourcing_channel'] = encoder.fit_transform(data['sourcing_channel'])
data['residence_area_type'] = encoder.fit_transform(data['residence_area_type'])
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

# Application de l'algorithme Isolation Forest
model = IForest(contamination=0.06)
model.fit(data_scaled)
data['anomaly'] = model.labels_

# √âvaluation des r√©sultats
print("Nombre d'anomalies d√©tect√©es : ", sum(data['anomaly'] == 1))
```

#### Conclusion et Recommandations

PyOD est une biblioth√®que puissante pour explorer et comparer diff√©rents algorithmes de d√©tection d'anomalies. Cependant, il est recommand√© de commencer par tester ces algorithmes sur des jeux de donn√©es exp√©rimentaux avant de les d√©ployer dans un contexte commercial, afin d'ajuster les param√®tres et de s'assurer que les mod√®les offrent une pr√©cision suffisante pour les anomalies et les non-anomalies.

En comprenant les forces et les faiblesses de chaque algorithme dans diff√©rents contextes, les praticiens peuvent mieux s√©lectionner l'outil adapt√© √† leurs besoins sp√©cifiques en mati√®re de d√©tection d'anomalies, minimisant ainsi les risques de d√©cisions incorrectes et am√©liorant la gestion proactive des fraudes et autres irr√©gularit√©s.

[Retour en haut](#table-des-mati√®res)



---


# Annexe 1 :  Comprendre les Anomalies et les Outliers ?

## Introduction

Dans le cadre de l'analyse de donn√©es, il est essentiel de comprendre les concepts d'anomalies et d'outliers. Ces notions sont fondamentales pour des applications telles que la d√©tection de fraude, la maintenance pr√©dictive, et l'am√©lioration de la qualit√© des donn√©es. Ce document clarifie la distinction entre anomalies et outliers, et explique leur importance dans l'analyse de donn√©es.

## D√©finition des Concepts

### Anomalie

Une **anomalie** est un point de donn√©es ou un ensemble de points qui se distingue par un comportement inhabituel ou inattendu par rapport au reste du jeu de donn√©es. Les anomalies peuvent signaler des √©v√©nements rares, des erreurs, ou des comportements qui ne suivent pas la tendance g√©n√©rale.

#### Types d'anomalies :
1. **Anomalies bas√©es sur le temps** : Les points de donn√©es sont d√©pendants du temps. Par exemple, les variations du prix de l'essence sur une p√©riode.
2. **Anomalies non bas√©es sur le temps** : Les points de donn√©es ne d√©pendent pas du temps. Par exemple, le prix d'un appartement en fonction de divers facteurs.
3. **Anomalies d'image** : Anomalies d√©tect√©es dans des ensembles d'images, souvent utilis√©es dans la vision par ordinateur.

### Outlier

Un **outlier** est un point de donn√©es qui se situe loin de la majorit√© des autres points dans un jeu de donn√©es. Il est souvent identifi√© statistiquement par sa distance par rapport √† d'autres points.

### Relation entre Outliers et Anomalies

- **Dans certains cas** : Chaque outlier est consid√©r√© comme une anomalie. Cette approche simplifie l'analyse et aide √† identifier rapidement des points de donn√©es potentiellement probl√©matiques. Par exemple, dans un **datawarehouse bancaire**, la d√©tection de transactions financi√®res est tr√®s stricte. Tout montant qui s'√©carte significativement des transactions habituelles d'un client peut √™tre consid√©r√© comme une anomalie pour pr√©venir les fraudes ou identifier des erreurs. De m√™me, dans les syst√®mes de **pr√©vention des fraudes par carte de cr√©dit**, chaque transaction consid√©r√©e comme un outlier par rapport aux habitudes d'achat d'un client (comme un montant inhabituel ou une localisation g√©ographique √©trange) est automatiquement flagu√©e comme une anomalie et n√©cessitera une v√©rification suppl√©mentaire.
- **Dans un contexte plus large** : Un outlier n'est pas n√©cessairement une anomalie. Par exemple, une transaction exceptionnellement √©lev√©e peut √™tre normale pour certains clients et ne serait donc pas consid√©r√©e comme une anomalie.

### Valeurs Nulles

Une **valeur nulle** repr√©sente l'absence de donn√©es. Bien qu'une valeur nulle ne soit pas automatiquement une anomalie, elle peut en indiquer une si elle appara√Æt dans un contexte o√π aucune donn√©e ne devrait √™tre manquante. Par exemple, un champ obligatoire laiss√© vide dans une base de donn√©es pourrait √™tre interpr√©t√© comme une anomalie.

## M√©thodes de D√©tection des Anomalies

### Algorithmes Supervis√©s

Les algorithmes supervis√©s sont utilis√©s lorsque des exemples d'anomalies pass√©es sont disponibles. Ils permettent de classifier de nouveaux points de donn√©es en fonction de ces r√©f√©rences.

### Algorithmes Non Supervis√©s

Les algorithmes non supervis√©s sont utilis√©s lorsque aucune r√©f√©rence pass√©e n'est disponible. Ils sont souvent pr√©f√©r√©s en entreprise car les donn√©es pass√©es ne sont pas toujours fiables ou disponibles. Ces algorithmes, bas√©s sur des clusters ou d'autres m√©thodes, d√©tectent des comportements inattendus sans connaissance pr√©alable.

## Exemples Pratiques

1. **Jeux de donn√©es bas√©s sur le temps** : Transactions bancaires √† diff√©rents moments.
2. **Jeux de donn√©es non bas√©s sur le temps** : Prix des appartements en fonction de divers facteurs.

La d√©tection d'anomalies dans les jeux de donn√©es bas√©s sur le temps est particuli√®rement utile pour identifier des √©v√©nements rares mais critiques, comme la maintenance pr√©dictive dans l'industrie.

### Exemples concrets o√π les outliers sont toujours des anomalies

1. **Datawarehouse bancaire** : Dans une banque, les transactions financi√®res sont rigoureusement surveill√©es. Si une transaction pr√©sente un montant qui d√©vie fortement des habitudes d'un client, elle est automatiquement consid√©r√©e comme une anomalie. Cette approche stricte permet de d√©tecter rapidement les activit√©s frauduleuses ou les erreurs de saisie.
  
2. **Pr√©vention des fraudes par carte de cr√©dit** : Les syst√®mes de d√©tection de fraude consid√®rent chaque outlier comme une anomalie potentielle. Par exemple, si un client qui effectue habituellement de petites transactions locales r√©alise soudainement un achat important √† l'√©tranger, cela sera marqu√© comme une anomalie, et une alerte sera d√©clench√©e.

3. **Analyse des risques d'assurance** : Les compagnies d'assurance utilisent des mod√®les o√π chaque outlier dans les r√©clamations (comme un montant de sinistre tr√®s √©lev√© ou une fr√©quence de r√©clamations inhabituelle) est imm√©diatement consid√©r√© comme une anomalie. Cela permet de r√©duire les risques de fraude ou de fausses d√©clarations.

## Conclusion

Dans l'analyse de donn√©es, bien comprendre la diff√©rence entre anomalies et outliers est crucial. Si, dans certains cas, chaque outlier est consid√©r√© comme une anomalie, cette r√®gle peut ne pas s'appliquer dans toutes les situations. Il est important de choisir les bons outils et m√©thodes pour d√©tecter efficacement ces ph√©nom√®nes, en tenant compte des sp√©cificit√©s de votre jeu de donn√©es et du contexte de l'analyse.

---



# Annexe 2 :  Comprendre les Anomalies et les Outliers ?


**Dans certains cas, par exemple ou le contexte est stricte** : Chaque outlier est consid√©r√© comme une anomalie. Cette approche simplifie l'analyse et aide √† identifier rapidement des points de donn√©es potentiellement probl√©matiques. 

### Exemples de contextes stricts :

1. **Datawarehouse bancaire** : Dans un environnement bancaire, la surveillance des transactions financi√®res est extr√™mement rigoureuse. Toute transaction qui d√©vie significativement des habitudes d'un client, que ce soit par son montant ou sa localisation, est automatiquement consid√©r√©e comme une anomalie. Par exemple, si un client effectue habituellement des transactions de faible montant et qu'une transaction soudainement √©lev√©e appara√Æt, cela est imm√©diatement flagu√© pour une enqu√™te approfondie, afin de pr√©venir les fraudes ou de corriger des erreurs potentielles.

2. **Pr√©vention des fraudes par carte de cr√©dit** : Dans les syst√®mes de d√©tection de fraude par carte de cr√©dit, chaque transaction identifi√©e comme un outlier est imm√©diatement trait√©e comme une anomalie. Par exemple, un achat important r√©alis√© dans un pays o√π le client n'a jamais voyag√© ou une s√©rie de petites transactions effectu√©es en peu de temps dans diff√©rents endroits peut indiquer une activit√© frauduleuse. Ces anomalies d√©clenchent g√©n√©ralement des alertes automatiques et peuvent entra√Æner la suspension de la carte jusqu'√† ce que la situation soit clarifi√©e.

3. **Signes vitaux en m√©decine** : Dans le domaine m√©dical, les signes vitaux des patients (tels que la fr√©quence cardiaque, la tension art√©rielle, la temp√©rature corporelle, etc.) sont surveill√©s en temps r√©el. Chaque outlier est trait√© comme une anomalie potentiellement critique. Par exemple, une chute soudaine de la pression art√©rielle ou une augmentation rapide de la temp√©rature corporelle par rapport aux valeurs normales du patient est imm√©diatement consid√©r√©e comme une anomalie. Cette d√©tection pr√©coce permet aux professionnels de la sant√© de r√©agir rapidement pour √©viter des complications graves ou des urgences m√©dicales.

4. **Surveillance industrielle et maintenance pr√©dictive** : Dans les environnements industriels, les capteurs surveillent en continu les performances des machines. Si un capteur enregistre une temp√©rature ou une vibration qui d√©vie significativement des valeurs normales, cela est trait√© comme une anomalie. Par exemple, une machine qui fonctionne habituellement √† une certaine temp√©rature pourrait indiquer un probl√®me m√©canique si la temp√©rature d√©passe soudainement ce seuil. L'identification de ces anomalies permet une intervention rapide, pr√©venant ainsi les pannes co√ªteuses et les arr√™ts de production non planifi√©s.

---

# Annexe 3 :  La Fin du Mythe de la Black Box en Machine Learning : Mythe ou R√©alit√© ?

Dans le monde du machine learning, la notion de "bo√Æte noire" a toujours √©t√© un sujet de pr√©occupation. L'id√©e est simple : les mod√®les complexes, tels que les r√©seaux de neurones profonds, prennent des d√©cisions que m√™me leurs cr√©ateurs peuvent avoir du mal √† comprendre ou √† expliquer. Cette opacit√© a conduit √† des critiques sur la confiance que l'on peut accorder √† ces mod√®les, surtout dans des domaines critiques comme la sant√©, la finance ou la justice.

Cependant, avec l'√©mergence d'outils d'explicabilit√© comme SHAP (SHapley Additive exPlanations), certains affirment que nous avons r√©solu le probl√®me de la bo√Æte noire. Mais est-ce vraiment le cas ? La fin de la bo√Æte noire est-elle une r√©alit√© ou un mythe ?

#### SHAP : Un Pas en Avant Vers l'Explicabilit√©

SHAP est une m√©thode bas√©e sur la th√©orie des jeux qui attribue une valeur de Shapley √† chaque caract√©ristique d'un mod√®le, indiquant l'importance de cette caract√©ristique pour une pr√©diction donn√©e. Ce m√©canisme a r√©volutionn√© la mani√®re dont nous pouvons interpr√©ter les mod√®les complexes, permettant de fournir des explications pr√©cises et coh√©rentes sur les d√©cisions des mod√®les.

Avec SHAP, nous pouvons maintenant r√©pondre √† des questions comme "Pourquoi le mod√®le a-t-il pr√©dit que cet utilisateur ne rembourserait pas son pr√™t ?" en identifiant les caract√©ristiques sp√©cifiques qui ont conduit √† cette pr√©diction. Cela repr√©sente un progr√®s significatif par rapport √† la situation pr√©c√©dente, o√π les mod√®les de r√©seaux de neurones √©taient souvent consid√©r√©s comme des bo√Ætes noires impenetrables.

#### L'Explicabilit√© : Une Solution Compl√®te ?

Cependant, il est essentiel de nuancer cette avanc√©e. Bien que SHAP et d'autres techniques d'explicabilit√© r√©duisent l'opacit√© des mod√®les, ils ne rendent pas ces mod√®les totalement transparents ou interpr√©tables dans tous les sens.

1. **Explicabilit√© vs. Interpr√©tabilit√©** : SHAP nous donne des explications sur les d√©cisions des mod√®les, mais il ne rend pas les mod√®les eux-m√™mes plus simples ou plus transparents. Un r√©seau de neurones reste un mod√®le complexe avec de nombreuses couches et des interactions non lin√©aires difficiles √† comprendre dans leur int√©gralit√©.

2. **Complexit√© des Explications** : Les valeurs de Shapley sont utiles, mais elles peuvent √™tre difficiles √† interpr√©ter, surtout pour les mod√®les avec des milliers de caract√©ristiques. Comprendre l'importance relative de chaque caract√©ristique et comment elles interagissent peut rapidement devenir un casse-t√™te.

3. **Approximation et Fiabilit√©** : Les explications fournies par SHAP sont des approximations bas√©es sur des mod√®les complexes. Ces approximations sont souvent tr√®s pr√©cises, mais elles ne sont pas parfaites. Dans certains cas, elles peuvent ne pas capturer toutes les subtilit√©s du mod√®le.

4. **Co√ªt Computationnel** : Utiliser SHAP pour expliquer un mod√®le complexe peut √™tre tr√®s co√ªteux en termes de temps de calcul et de ressources. Pour des mod√®les tr√®s grands ou des ensembles de donn√©es volumineux, cela peut poser des probl√®mes pratiques.

#### La Bo√Æte Noire : Un Probl√®me R√©volu ?

Dire que le probl√®me de la bo√Æte noire est "r√©volu" serait une exag√©ration. Nous avons fait des progr√®s √©normes gr√¢ce √† des outils comme SHAP, mais la complexit√© inh√©rente des mod√®les modernes signifie qu'il reste encore des d√©fis √† relever. 

En r√©alit√©, l'explicabilit√© n'est qu'une partie de la solution. Il est √©galement crucial de travailler sur la transparence des mod√®les, l'√©thique des d√©cisions automatis√©es, et l'interpr√©tabilit√© globale pour garantir que nous pouvons vraiment comprendre et faire confiance aux syst√®mes d'IA que nous d√©veloppons.

#### Conclusion

L'affirmation selon laquelle le probl√®me de la bo√Æte noire est r√©solu est un mythe partiellement vrai. Oui, nous avons des outils comme SHAP qui nous permettent de mieux comprendre les mod√®les complexes, mais cela ne signifie pas que tous les d√©fis li√©s √† l'opacit√© des mod√®les sont r√©solus. L'explicabilit√© est un pas en avant, mais la route vers une compr√©hension compl√®te et une transparence totale est encore longue. Il est important de continuer √† chercher des solutions qui allient puissance de pr√©diction et clart√© pour que la confiance dans les mod√®les de machine learning puisse v√©ritablement se d√©velopper.

L'histoire de la bo√Æte noire n'est pas encore termin√©e, mais avec les avanc√©es actuelles, nous sommes certainement en train d'√©crire son prochain chapitre.



