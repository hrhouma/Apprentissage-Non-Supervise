# Clustering Hiérarchique en Machine Learning

Le clustering hiérarchique est un autre algorithme de machine learning non supervisé, utilisé pour regrouper des ensembles de données non étiquetées en clusters. Il est également connu sous le nom d'analyse de cluster hiérarchique ou HCA (Hierarchical Cluster Analysis).

Dans cet algorithme, nous développons une hiérarchie de clusters sous la forme d'un arbre, et cette structure en forme d'arbre est appelée dendrogramme.

Parfois, les résultats du clustering K-means et du clustering hiérarchique peuvent sembler similaires, mais ils diffèrent en fonction de leur fonctionnement. Il n'est pas nécessaire de prédéterminer le nombre de clusters comme nous le faisons dans l'algorithme K-means.

La technique de clustering hiérarchique a deux approches :

- **Agglomérative** : L'agglomérative est une approche ascendante, dans laquelle l'algorithme commence par prendre tous les points de données comme des clusters individuels et les fusionne jusqu'à ce qu'il ne reste plus qu'un seul cluster.
- **Divisive** : L'algorithme divisif est l'inverse de l'algorithme agglomératif car il s'agit d'une approche descendante.

## Pourquoi le clustering hiérarchique ?
Comme nous avons déjà d'autres algorithmes de clustering tels que le K-means, pourquoi avons-nous besoin du clustering hiérarchique ? Comme nous l'avons vu dans le clustering K-means, il y a certains défis avec cet algorithme, tels que le nombre prédéterminé de clusters et la tendance à créer des clusters de la même taille. Pour résoudre ces deux défis, nous pouvons opter pour l'algorithme de clustering hiérarchique car, avec cet algorithme, nous n'avons pas besoin de connaître le nombre prédéterminé de clusters.

Dans ce sujet, nous allons discuter de l'algorithme de clustering hiérarchique agglomératif.

## Clustering Hiérarchique Agglomératif
L'algorithme de clustering hiérarchique agglomératif est un exemple populaire de HCA. Pour regrouper les ensembles de données en clusters, il suit une approche ascendante. Cela signifie que cet algorithme considère chaque ensemble de données comme un cluster individuel au début, puis commence à combiner les paires de clusters les plus proches. Il fait cela jusqu'à ce que tous les clusters soient fusionnés en un seul cluster contenant tous les ensembles de données.

Cette hiérarchie de clusters est représentée sous la forme d'un dendrogramme.

## Comment fonctionne le Clustering Hiérarchique Agglomératif ?
Le fonctionnement de l'algorithme AHC peut être expliqué en utilisant les étapes suivantes :

### Étape 1 : Créer chaque point de données comme un cluster individuel.
Disons qu'il y a N points de données, donc le nombre de clusters sera également N.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise/assets/10111526/cbcbde95-5f49-44c5-bcf1-1160a0912619)

### Étape 2 : Prendre les deux points de données ou clusters les plus proches et les fusionner pour former un seul cluster. Il y aura donc maintenant N-1 clusters.


![image](https://github.com/hrhouma/Apprentissage-Non-Supervise/assets/10111526/2f91a06e-781b-40db-a7a8-c9c672521ac7)

### Étape 3 : À nouveau, prendre les deux clusters les plus proches et les fusionner pour former un seul cluster. Il y aura N-2 clusters.
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise/assets/10111526/d7cfa0d4-aafe-4c70-902d-3fcd092448b8)




