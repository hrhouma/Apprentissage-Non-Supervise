# Algorithme de Clustering K-Means (SANS MATHÉMATIQUES)
- https://www.youtube.com/watch?v=5I3Ei69I40s
# 1-  Introduction

Nous allons présenter ici notre premier algorithme d'apprentissage automatique non supervisé utilisé pour le clustering : K-Means. Utilisons un exemple où nous avons deux caractéristiques pour segmenter les clients d'un site :
1. Le nombre de visites sur notre site.
2. Depuis combien de temps ce client est venu dans notre magasin.

# 2 -Fonctionnement de K-Means

# 2.1. Étape 1 : Initialisation des Centroïdes

Pour commencer, nous choisissons deux points aléatoires qui vont agir comme centres de gravité (centroïdes) de nos clusters. Imaginons que nous avons deux clusters : un en bleu et un en rose. 

# 2.2.  Étape 2 : Affectation des Points aux Clusters

Ensuite, pour chaque point de notre espace de données, nous déterminons à quel cluster il appartient en calculant la distance jusqu'au centroïde le plus proche. Les points sont affectés au cluster dont le centroïde est le plus proche. À la première itération, les points sont codés par couleur selon leur cluster.

# 2.3. Étape 3 : Ajustement des Centroïdes

Une fois que chaque point est affecté à un cluster, nous ajustons les centroïdes en les déplaçant vers la nouvelle moyenne des points de leur cluster. Par exemple, le centroïde rose est déplacé vers le centre des points roses, et le centroïde bleu vers le centre des points bleus.

# 2.4. Étape 4 : Répétition du Processus

Nous répétons le processus d'affectation et d'ajustement jusqu'à ce qu'aucun point ne change de cluster. À chaque itération, les centroïdes se déplacent de moins en moins jusqu'à ce qu'ils ne bougent plus, indiquant la convergence. 

# 3. Exemple de Convergence

- **Première Itération** : Initialisation des centroïdes et première affectation des points.
- **Deuxième Itération** : Ajustement des centroïdes et nouvelle affectation des points.
- **Troisième Itération** : Ajustement des centroïdes et réaffectation, jusqu'à ce que les centroïdes ne bougent plus.

Lorsque les centroïdes ne bougent plus, l'algorithme a convergé. Cela signifie qu'il a trouvé la structure optimale dans l'ensemble de données.

# 4 . Segmentation en Trois Clusters

Pour trois clusters, le processus est similaire, mais avec un centroïde supplémentaire. L'algorithme peut donner plusieurs solutions possibles, chacune étant une convergence stable mais différente en fonction des points initiaux choisis.

# 5.  Sensibilité aux Points Initiaux

K-Means est sensible au choix des points initiaux. Différentes configurations initiales peuvent conduire à des résultats différents. Il est donc important de choisir judicieusement les points initiaux ou d'utiliser des méthodes comme K-Means++ pour améliorer la sélection initiale des centroïdes.


# Algorithme de Clustering K-Means (AVEC DES IMAGES)

# Partie 1
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/8b30a74c-2a76-4aeb-a88d-9878c2c58fed)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/82d9a26e-abf4-4d32-aebb-0a275cd1558a)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/49fc6625-233a-4dfb-b195-b6c37ab69ccc)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/58c1ca4b-dd3d-48b2-93d2-1f23b204cd3c)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/305ec1e3-e7d8-4d66-b4ce-cb0526fba88b)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/51677896-c87f-4827-9106-f2f6bc908ff8)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/a2a916cc-3cc1-4ab7-adf3-b31f53b63aba)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/c7e88d16-d8bd-4e61-bcb7-6c7765713ba7)
bouger le centroide
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0dcebdfa-5930-4ecf-8c26-d8df27598470)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/5b8aa637-3b0a-445d-9c9f-26018d0c6157)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/53a961c4-2406-4ca6-b5dc-1c5220fc83f6)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0c65afd9-ce13-46ce-b9ee-8f804695a541)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/93e1a1e1-6883-48a8-ad11-b14a2d6bcf94)


# Partie 2
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0b562775-a4a7-4c65-9a7a-2fa13751d820)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/6239325e-394a-4ff5-bf0c-9d185b2719f3)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/4b4ad9c7-a9ce-4cb3-8af8-d257c43a5c92)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/a9371648-62d6-4b01-b2aa-84b485cca556)












# Algorithme de Clustering K-Means (AVEC MATHÉMATIQUES)
# Annexe 1 - Mathématiques + code de l'Algorithme de Clustering K-Means

# 1 - Introduction

L'algorithme K-Means est un algorithme d'apprentissage non supervisé utilisé pour le clustering, c'est-à-dire la segmentation de données en groupes (clusters) distincts. Il permet de révéler la structure sous-jacente des données en les organisant en clusters.

# 2 - Fonctionnement

### Étape 1 : Initialisation des Centroïdes

La première étape consiste à initialiser aléatoirement `K` centroïdes de clusters (`μ_1, μ_2, ..., μ_K`). Par exemple, si `K = 2`, on sélectionne au hasard deux points comme centroïdes initiaux.

### Étape 2 : Affectation des Points aux Clusters

Pour chaque point de données `x^(i)`, on calcule la distance à chaque centroïde `μ_k` et on attribue le point au centroïde le plus proche, déterminé par l'indice `c^(i)` :

$$
c^{(i)} = \arg \min_k \| x^{(i)} - \mu_k \|^2
$$

où `|| x^(i) - μ_k ||` représente la distance euclidienne entre le point `x^(i)` et le centroïde `μ_k`.

### Étape 3 : Ajustement des Centroïdes

Une fois que chaque point est affecté à un cluster, on recalcule les centroïdes `μ_k` en prenant la moyenne des points qui leur sont assignés :

$$
\mu_k = \frac{1}{|C_k|} \sum_{i \in C_k} x^{(i)}
$$

où `C_k` est l'ensemble des points assignés au cluster `k` et `|C_k|` est le nombre de points dans le cluster `k`.

### Étape 4 : Répétition du Processus

On répète les étapes d'affectation et d'ajustement jusqu'à ce qu'aucun point ne change de cluster, c'est-à-dire jusqu'à la convergence de l'algorithme.

# 3 -  Pseudocode de l'algorithme K-means

```python
def k_means(X, K):
    # Initialisation aléatoire des centroïdes
    centroids = initialize_random_centroids(X, K)
    previous_centroids = centroids.copy()
    converged = False
    
    while not converged:
        # Étape d'affectation
        labels = assign_labels(X, centroids)
        
        # Étape de mise à jour
        new_centroids = update_centroids(X, labels, K)
        
        # Vérifier la convergence
        if np.all(centroids == new_centroids):
            converged = True
        else:
            previous_centroids = centroids
            centroids = new_centroids
            
    return centroids, labels
```

# 4 - Objectif d'optimisation

L'algorithme K-Means optimise une fonction de coût qui est la somme des distances au carré entre les points et leurs centroïdes assignés :

$$
J = \sum_{i=1}^{m} \| x^{(i)} - \mu_{c^{(i)}} \|^2
$$

où `m` est le nombre de points de données, `x^(i)` est un point de données, `μ_{c^(i)}` est le centroïde du cluster assigné, et `|| · ||` représente la distance euclidienne.

# 5 - Conclusion

L'algorithme K-Means est une méthode efficace pour segmenter des données en clusters, révélant ainsi leur structure sous-jacente. Il est important de noter que les résultats peuvent varier en fonction de l'initialisation des centroïdes et du nombre de clusters choisi.




Citations:
- [1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/19265956/2d47ecc5-93f3-4413-9f78-67b716490796/paste.txt



