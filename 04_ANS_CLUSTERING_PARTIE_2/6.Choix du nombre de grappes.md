# Comment choisir le nombre optimal de clusters (k) dans l'algorithme k-means ?

- L'algorithme k-means est une technique de clustering non supervisée populaire qui partitionne les données en k clusters. Cependant, une des principales limitations de cet algorithme est qu'il nécessite de spécifier à l'avance le nombre de clusters k à former.
- Choisir une valeur appropriée de k est crucial pour obtenir un clustering significatif des données.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/c79da3cc-4b20-4360-81c1-ecf9a9824be5)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0ba4ac64-81e6-4821-8a1e-1fa803914b20)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/56cdb11c-3edb-45c7-b5ca-9f7428876688)



- Je vous propose quelques méthodes couramment utilisées pour déterminer le nombre optimal de clusters :

# 1. Méthode du coude (Elbow Method)


La méthode du coude est l'une des techniques les plus populaires pour estimer le nombre optimal de clusters. Elle consiste à exécuter l'algorithme k-means pour différentes valeurs de k, en calculant à chaque fois la somme des carrés des distances de chaque point à son centroïde de cluster (inertie intra-cluster). On trace ensuite un graphique de l'inertie intra-cluster en fonction du nombre de clusters k.
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0c88e4ee-fe43-416f-9551-0cf3e79f7a76)
La courbe obtenue décroît généralement de manière prononcée au début, puis commence à se stabiliser à un certain point, formant un "coude". Le nombre optimal de clusters k est choisi au niveau de ce coude, où l'ajout de clusters supplémentaires n'apporte qu'une faible amélioration de l'inertie intra-cluster.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/a5ddadc1-800c-446a-a3e5-db8abd3e82ab)
Bien que cette méthode soit simple et intuitive, elle peut être subjective et sensible aux valeurs aberrantes. De plus, le coude n'est pas toujours évident à identifier, en particulier lorsque la courbe est lisse.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/ede03ba6-eff5-4270-90ae-658c34c28a8d)


![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/72ee23e3-80aa-4bdb-b12f-c5a7cfad1104)

# 2. Coefficient de silhouette

Le coefficient de silhouette est une mesure de la similitude d'un point de données avec son propre cluster par rapport aux autres clusters. Il varie entre -1 et 1, où une valeur proche de 1 indique que le point de données est bien affecté à son cluster.

Pour trouver le nombre optimal de clusters, on calcule le coefficient de silhouette moyen pour différentes valeurs de k. Le nombre de clusters k qui maximise le coefficient de silhouette moyen est considéré comme optimal.

Cette méthode prend en compte à la fois la compacité des clusters (cohésion) et la séparation entre les clusters. Cependant, elle peut être coûteuse en calcul pour de grands ensembles de données.

#  3. Statistique d'écart (Gap Statistic) 
- Cette méthode est plus robuste que la méthode du coude, mais elle nécessite de simuler des données de référence, ce qui peut être coûteux en temps de calcul.

La statistique d'écart compare la somme des carrés intra-cluster pour différentes valeurs de k avec leur distribution attendue sous une hypothèse nulle de référence (généralement des données uniformément réparties). Le nombre optimal de clusters est celui qui maximise l'écart entre le log(Wk) observé et son espérance sous l'hypothèse nulle.


## Point de vulgarisation : 
- La statistique d'écart est une méthode utilisée pour déterminer le nombre optimal de clusters dans un ensemble de données. 
- Pour mieux comprendre cette méthode, imaginons un exemple de la vie quotidienne.

### Exemple de la vie quotidienne : Organisation d'une fête d'anniversaire

Supposons que vous organisez une fête d'anniversaire et que vous avez une liste d'invités de différents groupes d'amis (collègues, amis d'enfance, voisins, etc.). Vous voulez organiser des tables pour que chaque invité soit assis avec des personnes avec qui ils s'entendent bien. Le but est de minimiser les conflits et de maximiser le plaisir.

**Étape 1 : Déterminer les clusters (tables)**
Vous essayez différentes configurations pour déterminer combien de tables (clusters) vous devriez avoir. Par exemple, vous commencez avec 2 tables, puis 3 tables, et ainsi de suite.

**Étape 2 : Calculer la somme des carrés intra-cluster (Wk)**
Pour chaque configuration, vous évaluez à quel point les invités de chaque table sont homogènes en termes d'amitiés (la somme des carrés intra-cluster, Wk). Plus cette somme est faible, plus les invités à une même table sont proches les uns des autres.

**Étape 3 : Simulation de l'hypothèse nulle**
Ensuite, vous simulez plusieurs configurations de tables aléatoires en supposant que les invités sont répartis de manière uniforme, c'est-à-dire sans aucune relation d'amitié. Vous calculez Wk pour ces configurations aléatoires.

**Étape 4 : Calculer l'écart**
Vous comparez le log(Wk) observé pour vos configurations réelles avec celui des configurations aléatoires. L'écart est la différence entre le log(Wk) observé et l'espérance de log(Wk) sous l'hypothèse nulle.

**Étape 5 : Déterminer le nombre optimal de tables**
Le nombre optimal de tables (clusters) est celui qui maximise cet écart, car cela signifie que cette configuration est bien meilleure que ce à quoi on pourrait s'attendre si les invités étaient répartis au hasard.

### Illustration simplifiée

Imaginons que vous ayez testé pour 2, 3, 4, et 5 tables, et voici ce que vous avez trouvé :

- Pour 2 tables : log(Wk) observé = 4.5, log(Wk) attendu sous hypothèse nulle = 5.0
- Pour 3 tables : log(Wk) observé = 3.8, log(Wk) attendu sous hypothèse nulle = 4.5
- Pour 4 tables : log(Wk) observé = 3.0, log(Wk) attendu sous hypothèse nulle = 3.8
- Pour 5 tables : log(Wk) observé = 2.5, log(Wk) attendu sous hypothèse nulle = 3.0

Les écarts sont :

- Pour 2 tables : 5.0 - 4.5 = 0.5
- Pour 3 tables : 4.5 - 3.8 = 0.7
- Pour 4 tables : 3.8 - 3.0 = 0.8
- Pour 5 tables : 3.0 - 2.5 = 0.5

# Le plus grand écart est pour 4 tables avec un écart de 0.8. 
- Donc, le nombre optimal de tables (clusters) pour organiser vos invités est 4.

# distribution attendue sous une hypothèse nulle de référence ?
- Pour vulgariser la notion de "distribution attendue sous une hypothèse nulle de référence", imaginons encore notre exemple de la fête d'anniversaire.

### Hypothèse nulle de référence

L'hypothèse nulle de référence, c'est comme dire : "Et si mes invités étaient répartis complètement au hasard, sans tenir compte des relations d'amitié ?". Cela signifie que nous voulons savoir ce qui se passerait si nous ignorions complètement qui connaît qui et mettions les invités aux tables de manière totalement aléatoire.

### Distribution attendue sous cette hypothèse

La "distribution attendue" sous cette hypothèse, c'est ce que nous nous attendrions à voir si cette répartition aléatoire se produisait. Nous faisons cela en simulant plusieurs fois cette répartition aléatoire. 

### Exemple simplifié

1. **Simulation** : Disons que vous simulez dix fois la répartition des invités en les assignant aux tables au hasard. Pour chaque simulation, vous calculez à quel point les invités à chaque table sont proches les uns des autres en termes d'amitié (c'est la mesure de Wk).

2. **Calcul des Wk** : Voici les valeurs que vous pourriez obtenir pour les dix simulations aléatoires :
   - Simulation 1 : Wk = 6.0
   - Simulation 2 : Wk = 5.8
   - Simulation 3 : Wk = 6.1
   - Simulation 4 : Wk = 5.9
   - Simulation 5 : Wk = 6.2
   - Simulation 6 : Wk = 6.0
   - Simulation 7 : Wk = 6.1
   - Simulation 8 : Wk = 5.7
   - Simulation 9 : Wk = 5.9
   - Simulation 10 : Wk = 6.0

3. **Espérance sous l'hypothèse nulle** : Vous calculez la moyenne de ces valeurs pour obtenir l'espérance (ou la valeur attendue) de Wk sous l'hypothèse nulle. Dans ce cas :
   - Moyenne de Wk = (6.0 + 5.8 + 6.1 + 5.9 + 6.2 + 6.0 + 6.1 + 5.7 + 5.9 + 6.0) / 10 = 5.97

### Comparaison

Maintenant, vous comparez le Wk observé pour vos configurations réelles de tables avec cette valeur moyenne attendue (5.97). Si votre Wk observé est beaucoup plus bas, cela signifie que vos invités sont beaucoup mieux regroupés que ce que l'on pourrait attendre par hasard, indiquant que vous avez probablement trouvé un bon nombre de tables (clusters).

- En résumé, la "distribution attendue sous une hypothèse nulle de référence" est simplement une façon de dire : "Voici ce à quoi nous nous attendrions si tout était réparti au hasard", et nous l'utilisons comme base de comparaison pour évaluer nos véritables regroupements.


- Cette méthode est plus robuste que la méthode du coude car elle prend en compte une hypothèse de référence (invités répartis uniformément) et évalue comment vos configurations réelles se comparent à cette référence. Cependant, elle nécessite des simulations qui peuvent être coûteuses en temps de calcul.


#  4. Connaissances du domaine

Dans certains cas, le nombre de clusters peut être déterminé par des connaissances préalables sur le domaine d'application ou par des contraintes métier. Par exemple, dans la segmentation de la clientèle, le nombre de clusters peut être choisi en fonction de critères marketing ou de stratégies de vente.

En pratique, il est souvent recommandé d'utiliser plusieurs de ces méthodes en parallèle et de combiner les résultats avec une expertise du domaine pour choisir le nombre optimal de clusters. De plus, il est important de garder à l'esprit que le clustering est un processus exploratoire et que le nombre de clusters peut être ajusté en fonction des besoins et des interprétations.

Citations:
- [1] https://openclassrooms.com/fr/courses/4525281-realisez-une-analyse-exploratoire-de-donnees/5177935-decouvrez-l-algorithme-k-means
- [2] https://datascientest.com/algorithme-des-k-means
- [3] https://fastercapital.com/fr/contenu/Analyse-de-cluster---techniques-d-analyse-de-cluster---des-K-moyennes-au-clustering-hierarchique.html
- [4] https://blent.ai/blog/a/k-means-comment-ca-marche
- [5] https://www.youtube.com/watch?v=0NqAmRzqeoE
- [6] https://stacklima.com/methode-du-coude-pour-une-valeur-optimale-de-k-en-kmeans/
- [7] https://fastercapital.com/fr/sujet/choisir-le-bon-nombre-de-clusters-%28k%29.html
- [8] https://fr.linkedin.com/advice/0/how-do-you-choose-best-k-elbow-method-cluster?lang=fr
- [9] https://ichi.pro/fr/methode-du-coude-vs-coefficient-de-silhouette-pour-determiner-le-nombre-de-clusters-56878238252782


# Annexe résumé pour déterminer le Nombre de Clusters \( K \) en K-means

L'algorithme K-means nécessite que vous choisissiez le nombre de clusters \( K \) que vous souhaitez trouver dans votre ensemble de données. Mais comment décidez-vous du nombre de clusters à utiliser ? Voulez-vous deux clusters, trois clusters, cinq clusters ou même dix clusters ? Examinons ce problème plus en détail.

# 1 - Ambiguïté du Nombre de Clusters

Pour de nombreux problèmes de clustering, la bonne valeur de \( K \) est souvent ambiguë. Si vous montrez le même ensemble de données à différentes personnes et que vous leur demandez combien de clusters elles voient, certaines personnes diront qu'il semble y avoir deux groupes distincts et elles auront raison. D'autres diront qu'il y a quatre groupes distincts et elles auront également raison. Le clustering étant un algorithme d'apprentissage non supervisé, il n'y a pas de réponse "correcte" unique en termes de nombre de clusters.

# 2 - Méthode du Coude

Une des méthodes couramment mentionnées pour choisir le nombre de clusters est la méthode du coude. Pour appliquer cette méthode, vous pouvez exécuter K-means avec diverses valeurs de \( K \) et tracer la fonction de coût (ou fonction de distorsion) \( J \) en fonction du nombre de clusters. Ce que vous observez souvent est que lorsque vous avez très peu de clusters, la fonction de coût \( J \) est élevée et, à mesure que vous augmentez le nombre de clusters, elle diminue rapidement puis plus lentement.

Par exemple, si la courbe de la fonction de coût ressemble à ceci :
```
J
|
|         _______
|       /
|     /
|___/
|__________ K
```
Le point où la diminution devient plus lente est appelé le "coude" de la courbe. Dans cet exemple, le coude se situe autour de trois clusters, donc vous pourriez choisir \( K = 3 \).

# 3 - Limites de la Méthode du Coude

Cependant, cette méthode n'est pas toujours fiable. Pour de nombreuses applications, le bon nombre de clusters est vraiment ambigu et la courbe de la fonction de coût ne présente pas toujours un coude clair. De plus, choisir \( K \) pour minimiser la fonction de coût \( J \) n'est pas une bonne technique, car cela vous inciterait presque toujours à choisir la plus grande valeur possible de \( K \). En effet, avoir plus de clusters réduit presque toujours la fonction de coût \( J \).

# 4 -  Évaluation Basée sur l'Utilisation Ultérieure

Une approche plus pratique consiste à évaluer K-means en fonction de ses performances pour une utilisation ultérieure ou en aval. Par exemple, si vous utilisez K-means pour déterminer les tailles de t-shirts, vous pouvez comparer les résultats pour \( K = 3 \) (petit, moyen, grand) et \( K = 5 \) (très petit, petit, moyen, grand, très grand). La décision entre trois ou cinq tailles de t-shirts peut être prise en fonction de ce qui convient le mieux à votre entreprise, en tenant compte des coûts supplémentaires de fabrication et d'expédition de cinq tailles au lieu de trois.

# 5 - Exercice Pratique : Compression d'Images

Un exemple visuel amusant de K-means est l'application à la compression d'images. Vous pouvez exécuter K-means avec différentes valeurs de \( K \) et observer le compromis entre la qualité de l'image compressée et la quantité de compression. Cela vous permet de choisir manuellement la meilleure valeur de \( K \) en fonction de la qualité d'image souhaitée et de la taille de fichier acceptable.

# 6 - Conclusion

Choisir le bon nombre de clusters \( K \) est souvent un processus ambigu et subjectif. En fin de compte, l'évaluation basée sur l'utilisation pratique et les exigences spécifiques de votre application est la meilleure approche. En utilisant K-means avec plusieurs valeurs de \( K \) et en comparant les résultats, vous pouvez prendre une décision éclairée qui répond le mieux à vos besoins.

---

# Annexe 2 -  Exécution de K-means avec Initialisations Multiples

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/da74f81c-138d-46ac-a114-d8901b8b8e25)

---

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/b7e35a1d-2418-45fc-a874-13ee0b77868d)
