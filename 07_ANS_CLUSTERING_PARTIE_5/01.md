### Cours sur les Métriques Utilisées dans l'Apprentissage Non Supervisé

#### Introduction
L'apprentissage non supervisé est une méthode d'analyse des données utilisée pour découvrir des motifs cachés dans des données non étiquetées. Les métriques sont cruciales pour évaluer la qualité des clusters trouvés par des algorithmes comme K-means, DBSCAN, et l'analyse en composantes principales (PCA). Ce cours explore les principales métriques utilisées pour évaluer les algorithmes d'apprentissage non supervisé, avec des formules mathématiques et des exemples vulgarisés.

### Objectifs du Cours
1. Comprendre l'importance des métriques dans l'apprentissage non supervisé.
2. Découvrir les différentes métriques utilisées pour évaluer les clusters.
3. Apprendre à interpréter les résultats de ces métriques.
4. Appliquer ces métriques dans des exemples pratiques avec des algorithmes.

### Contenu du Cours

#### 1. Introduction aux Métriques de Clustering
- **Définition et importance des métriques dans l'apprentissage non supervisé**
- **Types de métriques** : métriques internes, externes, et relatives

#### 2. Métriques Internes
Les métriques internes évaluent la qualité des clusters en utilisant uniquement les données et la partition trouvée.

##### 2.1 Indice de Silhouette
- **Définition** : Mesure de la compacité et de la séparation des clusters.
- **Formule** :
  $$
  s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
  $$
  où :
  - \( a(i) \) est la distance moyenne entre \( i \) et tous les autres points du même cluster.
  - \( b(i) \) est la distance moyenne entre \( i \) et tous les points du cluster le plus proche.
- **Interprétation** : Valeur entre -1 et 1. Plus proche de 1 signifie de bons clusters, proche de -1 signifie de mauvais clusters.

**Exemple Vulgarisé** :
Imaginez que vous organisez une fête et que vous essayez de diviser vos invités en groupes pour qu'ils aient des conversations intéressantes. L'indice de silhouette vous aide à voir si chaque invité est dans le bon groupe ou non. Une valeur élevée signifie que vos invités sont bien regroupés, tandis qu'une valeur basse signifie que certains invités se sentent déplacés.

##### 2.2 Indice de Davies-Bouldin
- **Définition** : Ratio de la distance intra-cluster à la distance inter-cluster.
- **Formule** :
  $$
  DB = \frac{1}{n} \sum_{i=1}^{n} \max_{j \neq i} \left( \frac{s_i + s_j}{d(c_i, c_j)} \right)
  $$
  où :
  - \( s_i \) est la distance moyenne des points dans le cluster \( i \) à son centre.
  - \( d(c_i, c_j) \) est la distance entre les centres des clusters \( i \) et \( j \).
- **Interprétation** : Plus la valeur est basse, meilleure est la séparation des clusters.

**Exemple Vulgarisé** :
Reprenons l'exemple de la fête. L'indice de Davies-Bouldin mesure à quel point chaque groupe d'invités est serré et à quel point les groupes sont éloignés les uns des autres. Une valeur faible signifie que vos invités sont bien séparés en groupes distincts.

##### 2.3 Cohésion et Séparation
- **Cohésion** : Mesure de la compacité des clusters (somme des distances intra-cluster).
  $$
  \text{Cohésion} = \sum_{i=1}^{n} \sum_{x \in C_i} \| x - \mu_i \|^2
  $$
  où \( \mu_i \) est le centre du cluster \( i \).
- **Séparation** : Mesure de la distance entre les clusters (somme des distances inter-cluster).
  $$
  \text{Séparation} = \sum_{i=1}^{n} \sum_{j \neq i} \| \mu_i - \mu_j \|^2
  $$

**Exemple Vulgarisé** :
Pensez à la cohésion comme à la proximité des invités dans chaque groupe. Si les invités sont proches les uns des autres, la cohésion est élevée. La séparation est la distance entre les différents groupes. Si les groupes sont bien séparés, la séparation est élevée.

#### 3. Métriques Externes
Les métriques externes comparent les clusters obtenus avec une vérité terrain (labels connus).

##### 3.1 Indice de Rand Ajusté
- **Définition** : Mesure de la similarité entre deux partitions, ajustée pour les chances.
- **Formule** :
  $$
  ARI = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) - \mathbb{E}[\text{RI}]}
  $$
  où RI est l'indice de Rand brut et \( \mathbb{E}[\text{RI}] \) est la valeur attendue de RI.
- **Interprétation** : Valeurs entre -1 et 1. 1 signifie une correspondance parfaite, 0 signifie une correspondance aléatoire.

**Exemple Vulgarisé** :
Supposons que vous avez divisé les invités en groupes en fonction de leurs intérêts, et vous comparez votre division avec la liste de préférences des invités. L'indice de Rand ajusté mesure à quel point votre division correspond à la liste de préférences.

##### 3.2 NMI (Normalized Mutual Information)
- **Définition** : Mesure de l'information partagée entre les clusters trouvés et les vrais clusters.
- **Formule** :
  $$
  NMI = \frac{2 \cdot I(U; V)}{H(U) + H(V)}
  $$
  où \( I(U; V) \) est l'information mutuelle et \( H(U) \) et \( H(V) \) sont les entropies des partitions.
- **Interprétation** : Valeurs entre 0 et 1. 1 signifie une correspondance parfaite.

**Exemple Vulgarisé** :
Reprenons l'exemple des invités. La NMI mesure combien d'information est partagée entre votre division des invités et leurs préférences réelles. Une valeur élevée signifie que votre division correspond bien aux préférences.

#### 4. Métriques Relatives
Les métriques relatives comparent différentes partitions ou résultats obtenus avec des paramètres différents.

##### 4.1 Courbe d'Inertie pour K-means
- **Définition** : Somme des distances au carré des points au centre du cluster.
- **Formule** :
  $$
  \text{Inertie} = \sum_{i=1}^{k} \sum_{x \in C_i} \| x - \mu_i \|^2
  $$
  où \( k \) est le nombre de clusters et \( \mu_i \) est le centre du cluster \( i \).
- **Utilisation** : Déterminer le nombre optimal de clusters (méthode de l'épaule).

**Exemple Vulgarisé** :
Imaginez que vous essayez de trouver le bon nombre de groupes pour vos invités. La courbe d'inertie montre comment l'ajout de plus de groupes réduit la distance moyenne entre les invités et le centre de leur groupe. Vous recherchez un point où l'ajout de groupes supplémentaires n'améliore pas significativement la situation (l'épaule de la courbe).

##### 4.2 Validation Croisée en Clustering
- **Définition** : Évaluer la stabilité des clusters en utilisant des sous-échantillons des données.
- **Application** : Comparaison de partitions pour différents algorithmes de clustering.

**Exemple Vulgarisé** :
Supposons que vous divisez vos invités en groupes plusieurs fois en utilisant différentes méthodes. La validation croisée vous aide à voir si les groupes sont cohérents d'une méthode à l'autre.

#### 5. Exemple Pratique : Évaluation des Algorithmes de Clustering
- **Cas d'Étude : Données Iris**
  - Application de K-means, DBSCAN, et PCA
  - Calcul des différentes métriques (Indice de Silhouette, Indice de Davies-Bouldin, NMI)
  - Interprétation des résultats
- **Cas d'Étude : Données Clients**
  - Segmentation des clients avec K-means
  - Évaluation des clusters avec des métriques internes et externes
  - Ajustement des paramètres et réévaluation

### Conclusion
- Récapitulatif des principales métriques
- Importance de choisir les bonnes métriques en fonction des objectifs de l'analyse
- Conseils pour l'interprétation et l'application des résultats dans des projets réels

### Ressources Supplémentaires
- Liens vers des articles académiques et des tutoriels en ligne
- Codes sources et notebooks Python pour les exemples présentés
- Lectures recommandées pour approfondir les concepts

---

Ce cours vous donne une compréhension approfondie des différentes métriques utilisées dans l'apprentissage non supervisé, avec des formules mathématiques et des exemples vulgarisés pour faciliter la compréhension et l'application pratique.
