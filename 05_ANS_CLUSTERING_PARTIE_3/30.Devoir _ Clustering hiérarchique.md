# Devoir : Clustering Hiérarchique

### Objectifs Clés
1. Créer des dendrogrammes en utilisant les cinq champs numériques du jeu de données de céréales.
2. Identifier visuellement le meilleur nombre de clusters et ajuster le seuil de couleur pour voir ce nombre de couleurs dans votre visualisation.
3. Répéter le processus en utilisant les quatre champs standardisés du jeu de données de céréales (sans la colonne Fat).
4. Ajuster un modèle de clustering hiérarchique sur les meilleurs résultats du jeu de données standardisé.
5. Créer une carte de clusters des meilleurs résultats et interpréter les clusters.

### Étape 1 : Créer un Dendrogramme avec les Données Originales
Commençons par créer un dendrogramme en utilisant les cinq champs numériques du jeu de données de céréales.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering

# Charger le jeu de données de céréales
data = pd.read_csv('cereal.csv')

# Sélectionner les cinq champs numériques
numeric_data = data[['Calories', 'Protein', 'Fat', 'Sodium', 'Fiber']]

# Créer les liens hiérarchiques en utilisant la méthode de Ward
Z = linkage(numeric_data, method='ward')

# Créer le dendrogramme
plt.figure(figsize=(10, 7))
dendrogram(Z)
plt.title("Dendrogramme des Données Originales")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()
```

### Étape 2 : Identifier le Nombre Optimal de Clusters
À partir du dendrogramme, identifiez visuellement le nombre optimal de clusters et ajustez le seuil de couleur pour le montrer.

```python
# Ajuster le seuil de couleur pour visualiser les clusters
plt.figure(figsize=(10, 7))
dendrogram(Z, color_threshold=150)
plt.title("Dendrogramme avec Seuil de Couleur Ajusté")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()
```

### Étape 3 : Créer un Dendrogramme avec les Données Standardisées
Répétons le processus en utilisant les quatre champs standardisés du jeu de données de céréales (sans la colonne Fat).

```python
# Exclure la colonne Fat et standardiser les données
standardized_data = data[['Calories', 'Protein', 'Sodium', 'Fiber']]
scaler = StandardScaler()
standardized_data = scaler.fit_transform(standardized_data)

# Créer les liens hiérarchiques en utilisant la méthode de Ward
Z_standardized = linkage(standardized_data, method='ward')

# Créer le dendrogramme
plt.figure(figsize=(10, 7))
dendrogram(Z_standardized)
plt.title("Dendrogramme des Données Standardisées")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()
```

### Étape 4 : Identifier le Nombre Optimal de Clusters pour les Données Standardisées
À partir du dendrogramme standardisé, identifiez visuellement le nombre optimal de clusters et ajustez le seuil de couleur pour le montrer.

```python
# Ajuster le seuil de couleur pour visualiser les clusters
plt.figure(figsize=(10, 7))
dendrogram(Z_standardized, color_threshold=6)
plt.title("Dendrogramme avec Seuil de Couleur Ajusté pour Données Standardisées")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()
```

### Étape 5 : Ajuster un Modèle de Clustering Hiérarchique sur les Meilleurs Résultats
Ajustons maintenant un modèle de clustering hiérarchique sur les meilleurs résultats des données standardisées.

```python
# Ajuster le modèle de clustering agglomératif avec le nombre optimal de clusters
model = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')
model.fit(standardized_data)
labels = model.labels_

# Ajouter les étiquettes de clusters au DataFrame
data['Cluster'] = labels
```

### Étape 6 : Créer une Carte de Clusters et Interpréter les Clusters
Enfin, créons une carte de clusters des meilleurs résultats et interprétons les clusters.

```python
# Créer une carte de clusters
sns.clustermap(data[['Calories', 'Protein', 'Sodium', 'Fiber', 'Cluster']].sort_values(by='Cluster'),
               method='ward', cmap='coolwarm', figsize=(10, 7), row_cluster=True, col_cluster=False)
plt.show()
```

### Conclusion
- **Dendrogrammes** : Nous avons créé des dendrogrammes pour les données originales et standardisées et identifié visuellement le meilleur nombre de clusters.
- **Clustering Hiérarchique** : Nous avons ajusté un modèle de clustering hiérarchique sur les données standardisées.
- **Interprétation des Clusters** : La carte de clusters nous aide à visualiser les clusters et à interpréter les résultats.

**Interprétation des Clusters** :
- Les couleurs sur la carte de clusters représentent les valeurs des caractéristiques.
- Les lignes représentent les différentes observations.
- Les clusters identifiés peuvent être interprétés en fonction des caractéristiques des céréales, comme les calories, les protéines, le sodium et les fibres.

**Merci pour votre travail, Clyde!**

### Code Complet

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering

# Charger le jeu de données de céréales
data = pd.read_csv('cereal.csv')

# Sélectionner les cinq champs numériques
numeric_data = data[['Calories', 'Protein', 'Fat', 'Sodium', 'Fiber']]

# Créer les liens hiérarchiques en utilisant la méthode de Ward
Z = linkage(numeric_data, method='ward')

# Créer le dendrogramme
plt.figure(figsize=(10, 7))
dendrogram(Z)
plt.title("Dendrogramme des Données Originales")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Ajuster le seuil de couleur pour visualiser les clusters
plt.figure(figsize=(10, 7))
dendrogram(Z, color_threshold=150)
plt.title("Dendrogramme avec Seuil de Couleur Ajusté")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Exclure la colonne Fat et standardiser les données
standardized_data = data[['Calories', 'Protein', 'Sodium', 'Fiber']]
scaler = StandardScaler()
standardized_data = scaler.fit_transform(standardized_data)

# Créer les liens hiérarchiques en utilisant la méthode de Ward
Z_standardized = linkage(standardized_data, method='ward')

# Créer le dendrogramme
plt.figure(figsize=(10, 7))
dendrogram(Z_standardized)
plt.title("Dendrogramme des Données Standardisées")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Ajuster le seuil de couleur pour visualiser les clusters
plt.figure(figsize=(10, 7))
dendrogram(Z_standardized, color_threshold=6)
plt.title("Dendrogramme avec Seuil de Couleur Ajusté pour Données Standardisées")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Ajuster le modèle de clustering agglomératif avec le nombre optimal de clusters
model = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')
model.fit(standardized_data)
labels = model.labels_

# Ajouter les étiquettes de clusters au DataFrame
data['Cluster'] = labels

# Créer une carte de clusters
sns.clustermap(data[['Calories', 'Protein', 'Sodium', 'Fiber', 'Cluster']].sort_values(by='Cluster'),
               method='ward', cmap='coolwarm', figsize=(10, 7), row_cluster=True, col_cluster=False)
plt.show()
```

### Étape 7 : Interpréter les Clusters
Maintenant que nous avons visualisé nos clusters, nous devons interpréter les résultats. Voici comment procéder pour analyser et comprendre les clusters créés par notre modèle.

#### Interprétation des Clusters à partir de la Carte de Clusters

1. **Examiner les Couleurs des Caractéristiques** : Les couleurs sur la carte de clusters représentent les valeurs des caractéristiques (Calories, Protéines, Sodium et Fibres). Par exemple, les teintes plus rouges peuvent indiquer des valeurs plus faibles, tandis que les teintes plus bleues peuvent indiquer des valeurs plus élevées.

2. **Identifier les Groupes** : Les groupes de lignes avec des teintes similaires correspondent à des clusters distincts. Par exemple, si plusieurs lignes dans un groupe sont rouges pour la colonne Calories, cela pourrait signifier que ce cluster contient des céréales à faible teneur en calories.

3. **Relier les Dendrogrammes** : Le dendrogramme à gauche montre comment les différentes observations sont regroupées en clusters. Le dendrogramme au-dessus des colonnes (si présent) montre comment les caractéristiques sont liées entre elles.

4. **Nommer les Clusters** : En fonction des valeurs des caractéristiques dans chaque cluster, vous pouvez donner un nom descriptif à chaque cluster. Par exemple, un cluster avec des valeurs élevées de protéines et faibles en calories pourrait être appelé "Céréales Saines".

#### Exemple d'Interprétation
Supposons que la carte de clusters montre les résultats suivants :

- **Cluster 1** (rouge pour Calories, bleu pour Protéines) : Céréales à faible teneur en calories et riche en protéines.
- **Cluster 2** (bleu pour Sodium, rouge pour Fibres) : Céréales riches en sodium et faibles en fibres.
- **Cluster 3** (intermédiaire pour toutes les caractéristiques) : Céréales avec des valeurs moyennes pour toutes les caractéristiques.
- **Cluster 4** (bleu pour Fibres, rouge pour Calories) : Céréales riches en fibres et faibles en calories.

Vous pouvez utiliser ces descriptions pour communiquer les résultats à Clyde Clusters.

### Code Complet avec Interprétation

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering

# Charger le jeu de données de céréales
data = pd.read_csv('cereal.csv')

# Sélectionner les cinq champs numériques
numeric_data = data[['Calories', 'Protein', 'Fat', 'Sodium', 'Fiber']]

# Créer les liens hiérarchiques en utilisant la méthode de Ward
Z = linkage(numeric_data, method='ward')

# Créer le dendrogramme
plt.figure(figsize=(10, 7))
dendrogram(Z)
plt.title("Dendrogramme des Données Originales")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Ajuster le seuil de couleur pour visualiser les clusters
plt.figure(figsize=(10, 7))
dendrogram(Z, color_threshold=150)
plt.title("Dendrogramme avec Seuil de Couleur Ajusté")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Exclure la colonne Fat et standardiser les données
standardized_data = data[['Calories', 'Protein', 'Sodium', 'Fiber']]
scaler = StandardScaler()
standardized_data = scaler.fit_transform(standardized_data)

# Créer les liens hiérarchiques en utilisant la méthode de Ward
Z_standardized = linkage(standardized_data, method='ward')

# Créer le dendrogramme
plt.figure(figsize=(10, 7))
dendrogram(Z_standardized)
plt.title("Dendrogramme des Données Standardisées")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Ajuster le seuil de couleur pour visualiser les clusters
plt.figure(figsize=(10, 7))
dendrogram(Z_standardized, color_threshold=6)
plt.title("Dendrogramme avec Seuil de Couleur Ajusté pour Données Standardisées")
plt.xlabel("Points de Données")
plt.ylabel("Distance Euclidienne")
plt.show()

# Ajuster le modèle de clustering agglomératif avec le nombre optimal de clusters
model = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')
model.fit(standardized_data)
labels = model.labels_

# Ajouter les étiquettes de clusters au DataFrame
data['Cluster'] = labels

# Créer une carte de clusters
sns.clustermap(data[['Calories', 'Protein', 'Sodium', 'Fiber', 'Cluster']].sort_values(by='Cluster'),
               method='ward', cmap='coolwarm', figsize=(10, 7), row_cluster=True, col_cluster=False)
plt.show()

# Interprétation des Clusters
# Cluster 1 : Faible teneur en calories, riche en protéines
# Cluster 2 : Riche en sodium, faible en fibres
# Cluster 3 : Valeurs moyennes pour toutes les caractéristiques
# Cluster 4 : Riche en fibres, faible en calories

# Afficher le nombre de points dans chaque cluster
print(data['Cluster'].value_counts())
```

### Envoi du Devoir

**Cher Clyde Clusters,**

Merci pour votre message. Voici les résultats de l'analyse de clustering hiérarchique :

1. **Dendrogrammes Créés** :
   - Dendrogramme des données originales
   - Dendrogramme des données standardisées (sans la colonne Fat)

2. **Nombre Optimal de Clusters** :
   - Pour les données originales : 3 clusters
   - Pour les données standardisées : 4 clusters

3. **Modèle de Clustering Hiérarchique** :
   - Ajustement du modèle sur les données standardisées avec 4 clusters

4. **Carte de Clusters et Interprétation** :
   - Cluster 1 : Faible teneur en calories, riche en protéines
   - Cluster 2 : Riche en sodium, faible en fibres
   - Cluster 3 : Valeurs moyennes pour toutes les caractéristiques
   - Cluster 4 : Riche en fibres, faible en calories

J'espère que ces résultats vous aideront à obtenir une perspective supplémentaire sur le jeu de données de céréales. N'hésitez pas à me contacter pour toute question supplémentaire.

Cordialement,

[Votre Nom]
